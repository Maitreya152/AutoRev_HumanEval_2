{
    "7sMR09VNKU": {
        "gold_review": "**Summary**\nThe paper introduces a method for learning system dynamics from noisy observations by embedding states and controls into a space where the dynamics transition function is linear, with the application of Koopman operator theory (KOT). The primary contribution is a novel methodological framework that integrates optimal control principles with deep neural network-based embeddings to solve nonlinear control problems by translating them into linear representations in a lifted feature space. Experimental validations include simulation experiments on systems like pendulum and cartpole using linear-quadratic regulator (LQR) control design. Despite being well-motivated by challenging real-world control issues, the paper struggles with comparisons against well-established methods, the omission of broader baseline comparisons, and the non-universality of the approach across different system dynamics.\n\n**Strengths**\n- The paper effectively investigates the incorporation of states and controls into a dynamically linear feature space, aiding in the understanding of nonlinear dynamical systems.\n- The authors have executed detailed simulation experiments which validate their method and have provided sufficient details, making it possible for others to replicate these simulations.\n- The writing style of the paper enhances clarity, easing the comprehension of the nuances and contributions for readers.\n- Innovative use of DNNs to learn Koopman embeddings from images, simplifying the process of applying Koopman control while aiding generalization to arbitrary robotic systems.\n- A clear and thorough presentation of the network structure and its components, including the use of \"delayed\" coordinates in LQR, is well-defined, methodologically sound, and beneficial for less familiar audiences.\n- The paper includes a comprehensive section on related work, aiding in establishing the context and relevance of the research.\n\n**Weaknesses**\n- A significant limitation is noted in the computational challenge associated with solving the LQR, which may become overly costly for high-dimensional systems.\n- The proposed method lacks explicit comparisons with existing methods, particularly established control techniques like Nonlinear MPC, iLQR, PID, and others.\n- The applicability of the Koopman operator theory (KOT) presented is restricted primarily to control-affine systems, which limits its generalizability to various nonlinear systems that do not follow the control-affine form.\n- There seems to be an insufficient engagement with contemporary literature, especially with existing contributions around stability using Koopman-based learned matrices.\n- Research scope in demonstrations is narrow; primarily simple systems such as pendulums and cartpoles are considered, casting doubt on the method's generalizability and effectiveness on more complex or practical systems.\n- The paper's experiments section is relatively weak and limited, highlighting a dependency on having optimal trajectories for training, which risks undermining the approach's general applicability and novelty.\n\n**Questions**\n- Can the authors provide more detailed comparative studies with existing approaches to better highlight the advantages or improvements of the proposed method?\n- Would it be possible to include demonstrations on more general nonlinear examples, such as quadrotors, Vanderpol oscillators, or vehicle dynamics based on the bicycle model?\n- How is the approximation through Koopman-based lifted space justified for general nonlinear systems as described in the paper, particularly for systems that are not \"control-affine\"?\n- There are concerns about the plots in Figure 5 for the cartpole. Could you clarify if the control for this system is indeed the torque at the base of the pole and explicitly note any deviations from the classic cartpole setup?\n- What justifies the use of the proximal method of multipliers for solving the least squares problem in equation 6 over more conventional methods like iterative refinement?\n- How are the parameters M and T determined in your experiments, and what guidelines can you provide regarding their settings in practice?",
        "inference_review": "**Summary**\nThe paper presents a novel approach for learning the dynamics of nonlinear dynamical systems, particularly in control tasks, by integrating Koopman operator theory with neural networks and differentiable optimal control. The authors propose a method that not only learns the dynamics in a latent space but also incorporates control tasks within the learning process to ensure the controllability of the system. The approach is demonstrated through experiments on simulated pendulum and cartpole systems, showcasing the effectiveness of the method in learning predictive models and controlling the systems. However, the paper is criticized for its lack of novelty in methodology and insufficient experimental validation, particularly in real-world applications. The experiments are limited to simple simulated systems, and there is a lack of rigorous comparison with existing methods or detailed explanation of the differences in approach.\n\n**Strengths**\n- The paper is well-written and the methodology is clearly described, making it easy to follow.\n- The approach of learning a Koopman representation to handle nonlinear systems and incorporating control tasks in the learning process is innovative and potentially beneficial for practical applications.\n- The experiments conducted on simulated pendulum and cartpole systems are straightforward and demonstrate the effectiveness of the proposed method in controlling the systems.\n- The idea of including control tasks in the learning framework is novel and could be of interest for further exploration in the field.\n\n**Weaknesses**\n- The paper's contribution is not sufficiently novel, as it primarily combines existing methods of learning Koopman representations and optimal control techniques without introducing significant new elements.\n- The experimental validation is limited to simple simulated systems and does not extend to more complex or real-world scenarios, which could provide a clearer understanding of the method's applicability.\n- The results presented are not convincingly better than existing methods, and the paper does not provide a detailed comparison or analysis of why the proposed method performs better.\n- There is a lack of discussion on the theoretical aspects of the proposed approach, particularly in terms of controllability and the stability of the learned models.\n- The paper does not sufficiently discuss the challenges and limitations of the proposed method, such as scalability, computational complexity, and the potential for overfitting in complex systems.\n\n**Questions**\n- Can the authors clarify whether the proposed method has been tested on more complex or real-world systems beyond the simulated pendulum and cartpole systems?\n- What are the specific contributions of the proposed method compared to existing methods, and can the authors provide a detailed analysis of the differences in approach and results?\n- How does the proposed method ensure the stability and controllability of the learned models, and what are the potential limitations or challenges in applying this method to more complex systems?\n- Could the authors provide a more comprehensive experimental setup and results, including a detailed comparison with other existing methods to demonstrate the effectiveness of the proposed method?\n- What are the theoretical underpinnings of the proposed method, particularly in terms of the controllability and stability of the learned models?"
    },
    "BOm1RYdHHu": {
        "gold_review": "**Summary**\nThe paper introduces SAFHE (Secure Aggregation with Fully Homomorphic Encryption), a novel framework aimed at defending against both backdoor attacks and gradient inversion attacks in Federated Learning (FL). The approach cleverly utilizes fully homomorphic encryption to ensure that plaintext gradient updates or decryption keys remain concealed, thus safeguarding against unauthorized gradient reconstruction. Furthermore, the proposed system employs a mechanism to reject anomalously large weight updates\u2014a common indicator of backdoor attacks. The technique involves a continuous polynomial approximation (using Chebyshev polynomials) to filter gradient updates effectively within the encrypted domain, potentially enhancing the security of FL systems. In their evaluation, the authors demonstrate the theoretical applicability of their method in typical FL setups, though not without acknowledging certain assumptions and limitations in their experimental approach.\n\n**Strengths**\n- The paper proposes a clear, innovative concept by introducing a weighting function capable of accepting or rejecting client updates within a Federated Learning (FL) environment, operational in a Fully Homomorphic Encryption (FHE) setting.\n- The manuscript is well-written, facilitating a good understanding of the proposed ideas and methodologies for readers.\n- A detailed simulation study has been conducted, showcasing the application and impact of the proposed scheme.\n- The approximation methods through Chebyshev and Taylor series for non-polynomial continuous functions within the FHE context are correctly used.\n\n**Weaknesses**\n- The paper lacks theoretical support for the security and privacy aspects of the proposed scheme, particularly missing security proofs or detailed discussions on privacy guarantees.\n- There are some technical inaccuracies and presentation issues, such as inconsistencies in figures (e.g., Figure 2) and a mismatch between the title and main content focus.\n- The practical implementation and broader applicability of the proposed scheme appear to be oversimplified or not fully addressed, leading to an incomplete evaluation of its effectiveness in real-world scenarios.\n- The paper does not experimentally compare its approximation techniques (like using Chebyshev polynomials for the clip function) with other schemes or discuss in-depth variations and optimizations (e.g., polynomial degrees, parameters a,b,c,d) that could affect performance and security in FL environments.\n- The methodological contributions are questioned regarding their novelty and depth, as some techniques such as using sigmoids for clip functions are considered standard.\n\n**Questions**\n- Can the authors clarify whether the proposed scheme supports a malicious threat model, or detail its behavior under different security threats such as gradient inversion and backdoor attacks?\n- Regarding the technical aspects of your FHE implementation: Can the full computation of the function H and the l2-norm weight of a real gradient from your network be detailed in terms of precision and computational timing?\n- What specific values of parameters like 'c' were utilized in your experiments, and can you provide an ablation study with different values for these parameters?\n- How do the authors address the potential issue of adversaries optimizing their gradient updates to remain undetected (e.g., small yet malicious gradients), or the challenges posed by benign but statistically atypical gradients?\n- Is it possible to run additional experiments on a wider variety of datasets and FL models to better understand the robustness and generality of your approach?\n- Lastly, could the authors include more materials or references to better explain the application and limitations of FHE in preventing gradient inversion attacks, especially for reviewers less familiar with these concepts?",
        "inference_review": "**Summary**\nThe paper presents SAFHE, a method utilizing fully homomorphic encryption (FHE) for secure aggregation in federated learning (FL) to mitigate backdoor attacks and gradient inversion attacks. SAFHE employs a novel weighting function, based on Chebyshev polynomial approximations, to filter updates from clients, ensuring that only updates within a predetermined norm range are accepted. The method aims to preserve the privacy of client data by encrypting updates before aggregation and rejecting large updates that could compromise the model's integrity. While the method demonstrates effectiveness against these specific attacks in simulations and limited experimental settings, its real-world applicability and robustness against more sophisticated attacks remain questionable.\n\n**Strengths**\n- The paper addresses a significant and challenging problem of combining privacy and security in federated learning, which is crucial for widespread adoption in the real world.\n- The proposed method of using a sigmoid function to weight client updates is novel and shows promise in defending against backdoor attacks, as evidenced by the experiments conducted.\n- The paper is well-written, making it easy to follow, and it includes an extensive literature review that contextualizes the research effectively.\n- The inclusion of both theoretical analysis and empirical evaluations enhances the credibility and applicability of the findings.\n- The paper discusses the potential to use Chebyshev polynomials for other defense mechanisms in federated learning, which could be of interest to the community.\n\n**Weaknesses**\n- The paper's approach is limited to defending against specific attacks (backdoor and gradient inversion attacks), and it does not discuss the broader implications or potential vulnerabilities to other types of attacks.\n- The experimental setup is not robust, using a limited number of devices and a single data set (CIFAR-10), which may not accurately reflect the performance in more complex, real-world scenarios.\n- There is a lack of clarity on the practical implementation of the proposed methods, particularly regarding the computation and efficiency of the Chebyshev approximation in a fully homomorphic encryption (FHE) setting.\n- The paper does not sufficiently discuss or evaluate the potential impact of the method on the training process, particularly in terms of convergence and efficiency.\n- The evaluation of the method against adaptive attacks and more sophisticated attack models is missing, which is crucial for understanding its effectiveness in real-world scenarios.\n\n**Questions**\n- Could the authors elaborate on the potential impact of their method on the training process, specifically in terms of convergence speed and efficiency?\n- How does the method perform against more sophisticated and adaptive attacks, and can it be generalized to other types of attacks beyond those discussed in the paper?\n- Can the authors provide more details on the practical implementation of the Chebyshev approximation within an FHE setting, particularly regarding the computational overhead and accuracy of the approximation?\n- Would it be possible to extend the experiments to include more devices, different data sets, and additional architectures to better validate the method's effectiveness and scalability?\n- How does the method ensure the privacy of the clients' data, and what measures are in place to prevent the central server from accessing the clients' data during the aggregation process?"
    },
    "cXbnGtO0NZ": {
        "gold_review": "**Summary**\nThe paper discusses the generation of 3D graphs through a novel method called \"latent 3D graph diffusion,\" leveraging latent spaces achieved via cascaded 2D-3D graph autoencoders. The approach prioritizes learning a low-error reconstruction and symmetry invariance, which significantly improves the performance of diffusion processes, particularly in generating molecular structures. Both theoretical insights and practical implementations are extensively presented, underpinning the importance of dimensionality and quality of the latent space in enhancing diffusion efficiency and generation quality. The study extensively compares this method against existing ones, demonstrating marked improvements in generation speed and quality, especially in drug discovery contexts.\n\n**Strengths**\n- The paper demonstrates superior generation quality, rapid generation capabilities, and conditional generation proficiency in 3D graph generation, while enhancing robustness through regularization.\n- Well-written, with a straightforward and convincing rationale, supported by multiple numerical experiments showcasing the potential of conditional generation based on various properties.\n- Novel approach and theoretical foundation in addressing the use and implementation of latent spaces in 3D graph diffusion.\n- Innovative use of graph contrastive learning (GCL) to refine and enhance latent space representations for 3D graph autoencoders.\n- High versatility and adaptability of the model, validated through exhaustive evaluation in various scenarios like unconditional and conditional generation on quantum properties and protein targets.\n- Empirical validation showing the proposed method's superiority over existing techniques.\n\n**Weaknesses**\n- Limited generalization capability, emphasizing the need for improvement in diverse application scenarios.\n- Latent space and the necessity of its integration with the 3D graph representation lack detailed explanation and theoretical analysis.\n- Questions regarding the separation and individual influences of topological AE and geometric AE, as well as their integration challenges.\n- Some novelty concerns, as the work leverages existing 3D molecule generation setups with known concepts, potentially limiting groundbreaking contributions.\n- Lack of detailed experiments or ablation studies on the architectural decisions, particularly the difference between one-shot and cascaded AE, which could provide critical insights into their effectiveness and implementation.\n- The paper omits certain critical results and comparisons that could enhance the robustness of its conclusions, for instance, the comparison against more recent or advanced models like MIDI and another baseline refinement for fair comparison.\n- Issues in manuscript details, such as omission errors and unclear proofs, which could affect the readability and interpretability of findings.\n\n**Questions**\n- How can the generalization capability of the model be improved?\n- Could the authors clarify the specific influences of topological AE versus geometric AE and their integration method?\n- What innovations does the cascaded AE bring to the table when compared to traditional one-shot AE?\n- Can the effect of excluding latent space encoding be elaborated upon through an ablation study?\n- The decision behind selecting the Autoencoder (AE) baselines and the performance analysis involving newer models like MIDI should be explained.\n- Regarding the computational cost of AE training, specifically under the conditions of permutation and SE3 invariance, how does this impact the overall model performance and training time efficiency?\n- Further insights would be beneficial on how the model ensures low dimensionality, low reconstruction error, and preservation of group symmetry in the latent space.\n- How might the authors address the absence of results for \"Ours-GSSL\" in unconditional 3D molecular generation, and could they provide further statistical validation or comparative study for the same?",
        "inference_review": "**Summary**\nThe paper introduces Latent 3D Graph Diffusion (L3DG), a method that employs a 3D graph autoencoder to transform molecules into latent space, facilitating diffusion-based generation of 3D graphs. This approach is designed to address the challenges of generating valid and diverse 3D molecules by reducing the dimensionality of the data and enhancing the efficacy of diffusion models. The method has been tested on various benchmarks in drug discovery, demonstrating its ability to generate high-quality, valid, and diverse molecules. The authors highlight the efficiency of their method over existing diffusion-based methods, both in terms of computational time and quality of generated molecules. However, the paper faces criticism for insufficient theoretical backing, lack of rigorous experimental validation, and potential overfitting concerns.\n\n**Strengths**\n- The paper introduces a novel approach to 3D graph diffusion by leveraging a latent space, which allows for a significant reduction in the dimensionality of the data and enhances the efficacy of diffusion models.\n- The paper is well-organized and provides a comprehensive review of related work, which is essential for readers who may not be familiar with the field.\n- The proposed method demonstrates superior performance compared to existing diffusion-based methods, as evidenced by the results presented in Table 2.\n- The method is well-motivated and effectively addresses the challenges of generating valid and diverse 3D molecules, which is critical in drug discovery applications.\n- The paper is well-written, easy to follow, and includes several illustrative figures that help in understanding the proposed method.\n- The approach is innovative in its use of a latent space for 3D graph diffusion, which could potentially simplify the process of generating valid 3D molecules.\n\n**Weaknesses**\n- The theoretical underpinnings of the proposed method are weak, and there is a lack of rigorous mathematical analysis to support the claims made in the paper.\n- The experimental setup lacks diversity, as the diffusion-based methods compared in the study use different datasets and evaluation metrics, which can affect the fairness and validity of the comparison.\n- There is a lack of comparison with state-of-the-art methods such as GraphLDM and GeoLDM, which are relevant to the topic of 3D graph diffusion.\n- The paper does not provide a detailed analysis of the computational complexity of the proposed method, which is essential for understanding the practical applicability of the approach.\n- The manuscript suffers from several grammatical errors and typos, which can detract from the overall quality of the paper.\n- The experimental results in Table 4 suggest that the proposed method may be prone to overfitting, and there is a need for further validation to confirm the generalizability of the results.\n\n**Questions**\n- Can the authors provide a more detailed analysis of the theoretical underpinnings of the proposed method, specifically the mathematical justification for the use of a latent space in 3D graph diffusion?\n- How does the proposed method compare with other state-of-the-art methods in terms of computational complexity and runtime efficiency?\n- In the context of the experimental setup, why were certain datasets and evaluation metrics chosen, and can the authors provide a detailed justification for these choices?\n- Given the potential overfitting issues identified in Table 4, how do the authors plan to address this in future work to ensure the generalizability of the results?\n- Could the authors provide more clarity on the role and impact of the auxiliary objective in the diffusion model, and how it contributes to the overall performance of the proposed method?"
    },
    "Gny0PVtKz2": {
        "gold_review": "**Summary**\nThe paper introduces ConvFormer, a modification of the Transformer model using convolutional layers to address specific needs in sequential user modeling for recommender systems. Highlighting the limitations of self-attention in handling order sensitivity, maintaining a large receptive field, and ensuring a lightweight model, the authors argue for the superiority of simpler, alternative strategies. ConvFormer is proposed based on these criteria, showing consistent performance gains across benchmark datasets. Despite its strengths, the paper has been criticized for poor integration with the latest advancements, lack of clarity in experimental design, and a somewhat contradictory methodology. Some experiments lacked important baselines, and no online real-time experiments were conducted, obscuring its efficacy in practical scenarios.\n\n**Strengths**\n- The paper identifies the problem of self-attentive transformers when applied in user modeling and demonstrates consistent performance gains on most benchmark datasets.\n- The topic of finding alternatives to the self-attention mechanism is interesting and important, viewed as a good overview of the related literature.\n- The work contains a lot of empirical studies that allow greater granularity in analyzing the sequential learning process.\n- The idea of replacing self-attention with convolutional mechanisms has the potential to become a valuable contribution to the field.\n\n**Weaknesses**\n- The proposed method seems to be behind the recent progress in the machine learning community with outdated formulations.\n- The insufficient literature review does not address several existing advanced methodologies, and there are citations missing at crucial points in the paper.\n- The main experimental descriptions lack clarity, and the design of experiments and the methodology appear contradictory to the main claims of the paper.\n- Some straightforward baselines are missing from comparisons, which makes conclusions on superiority less convincing.\n- The paper does not include online real experiments, and only the ID feature was considered, limiting the generalizability of the findings.\n- There's no clear explanation of how the sequential order is taken into account, and how the causal structure of learning is preserved to avoid data leakage.\n- Computational aspects, such as the handling of long sequences and the impact of different loss functions on model comparisons, are not adequately addressed.\n\n**Questions**\n- 1. What's the relationship between the optimal kernel size (K) and the dataset sequence length?\n- 2. How would you choose the input sequence length?\n- 3. Will adding more blocks improve performance?\n- 4. Can you explain how the proposed modifications ensure the preservation of the sequential order, especially in aspects where contradictions are noted in the descriptions of models like SAR-O, SAR-P, and SAR-R?\n- 5. Could you provide a more detailed justification and expansion on the use of convolutional mechanisms as an alternative to self-attention specifically pertaining to their effectiveness in handling sequential data?\n- 6. Can the experimental scheme be modified to eliminate \"recommendations from the future\" leaks to verify the claimed superiority of the proposed model modifications?\n- 7. How does the proposed model account for different sequence lengths in practical applications like recommender systems where sequence lengths can vary significantly?",
        "inference_review": "**Summary**\nThe paper introduces ConvFormer, a novel architecture designed for sequential user modeling, emphasizing the importance of a large receptive field, lightweight architecture, and sensitivity to item order. It replaces the traditional self-attentive token mixer with a light TCN layer, which allows for efficient sequential modeling of user behavior. The model is validated through extensive experiments on four datasets, demonstrating its effectiveness and efficiency. The paper also provides a comprehensive analysis of the proposed design principles, showing how they contribute to the model's performance. However, there are concerns about the novelty of the design, the lack of a strong experimental comparison, and potential limitations in generalization across different domains.\n\n**Strengths**\n- The paper introduces a novel architecture, ConvFormer, which enhances performance in sequential user modeling tasks by focusing on a large receptive field, lightweight architecture, and order sensitivity.\n- It provides a clear and thorough explanation of the motivations and design choices behind the ConvFormer architecture, backed by rigorous experiments and ablation studies.\n- The manuscript is well-structured, making it easy to follow, and the inclusion of relevant baselines and ablation studies provides a robust evaluation of the proposed methods.\n- The model achieves state-of-the-art performance in sequential user modeling tasks, demonstrating its effectiveness.\n\n**Weaknesses**\n- The paper lacks a detailed discussion on how the proposed design principles are novel compared to existing literature, and the novelty of the ConvFormer architecture is not convincingly argued.\n- The experimental validation does not fully address the generalizability of the ConvFormer across various domains, such as in the recommendation of diverse products.\n- The paper could benefit from a more thorough comparison with other models like GCSAN, which shares similar design elements.\n- The absence of a discussion on the impact of other design choices, such as the use of MLP layers and the role of the last linear layer, limits the understanding of the model's performance.\n- The manuscript could be improved by including more detailed discussions on the model's limitations and potential applications in other domains.\n\n**Questions**\n- Can the authors elaborate on the novel aspects of the ConvFormer architecture compared to existing models?\n- How does the ConvFormer perform in different scenarios, particularly in recommending diverse products?\n- Could the authors discuss the choice of using MLP layers and the role of the last linear layer in the model's performance?\n- Are there any plans to extend the evaluation of ConvFormer to other domains beyond sequential user modeling?\n- How does the ConvFormer architecture compare with GCSAN, and what are the main differences and advantages of each model?"
    },
    "ljVCPV7jK3": {
        "gold_review": "**Summary**\nThe paper under review introduces a method to train fairness-enhancing interventions in environments with incomplete sensitive attributes. This method comprises two primary steps: the prediction of missing sensitive attributes via a student-teacher distillation proxy classifier, followed by a selection process based on the confidence threshold of these predictions. The instances identified with less uncertainty are then used to train the intervention. The approach is validated using several benchmark datasets aimed at assessing fairness. The methodology claims improvements in the fairness-accuracy tradeoff but faces criticism for its novelty and execution. Major concerns include the method's resemblance to basic attribute prediction techniques and an incomplete comparison with existing methods in the literature of fairness under similar constraints.\n\n**Strengths**\n- The paper addresses a critical issue in fairness research, focusing on studying fairness without full access to sensitive attributes, a prevalent and relevant problem in privacy-conscious environments.\n- The experiments are extensive, covering a diverse range of datasets and several classification tasks, and delve into the dynamics between the threshold and the encoding of sensitive information.\n- The research evidences a solid commitment to reproducibility through a detailed and transparent presentation of the experimental setup, datasets, and code availability.\n- The clarity and structure of the writing are commendable, enhancing readability and comprehension of the study.\n- Substantial citations of related works are utilized effectively to contextualize their method within the current literature landscape.\n\n**Weaknesses**\n- The technical novelty appears limited, with major techniques resembling baseline methods slightly enhanced by student-teacher transfer learning and filtering by prediction confidence thresholds.\n- There is a notable absence of comparisons with pertinent literature on fairness without full access to sensitive attributes, despite the existence of several relevant studies.\n- Ethical concerns arise from the methodology of predicting sensitive attributes, which might contravene privacy and legal standards.\n- Statements regarding the superiority of the framework over traditional models trained with access to the true sensitive attribute are not consistently supported across different fairness interventions as analyzed.\n- The method's sensitivity to the uncertainty threshold raises questions about its practical applicability and robustness, given that optimal threshold settings appear to be selected based on testing data rather than a standardized or validated method.\n\n**Questions**\n- Can the authors clarify the specific technical contributions of their methodology beyond the use of proxy classifiers with transfer learning and thresholding predictions?\n- Why were comparisons not drawn with established methods in the domain of fairness without full access to sensitive attributes, such as those outlined in the provided literature?\n- Given the ethical implications of predicting sensitive attributes, could the methodology be adjusted to utilize instances with high uncertainty regarding sensitive information, potentially enhancing ethical acceptability?\n- In practical applications, how would the optimal uncertainty threshold be determined to avoid reliance on trial and error?\n- How do the authors justify the approach's performance claims against interventions using actual sensitive attribute data, especially given variations highlighted in different figures and under varying experimental conditions?",
        "inference_review": "**Summary**\nThe paper introduces a novel framework to address fairness in machine learning when sensitive attributes are partially missing, a scenario termed as the \"demographic scarce regime.\" The proposed method leverages an attribute classifier to predict sensitive attributes with varying levels of confidence, which are then used in training a fair classifier. This approach is highlighted as an improvement over existing methods by showing superior fairness-accuracy trade-offs. The authors also explore the implications of uncertainty in sensitive attribute predictions, suggesting that models trained with such predictions tend to be fairer. Experiments across five datasets demonstrate the effectiveness of the proposed method, although concerns remain about its novelty and practical applicability due to the assumption of access to ground truth for sensitive attributes.\n\n**Strengths**\n- The paper addresses an important and challenging issue of fairness in machine learning with missing sensitive attributes, a scenario often overlooked in existing literature.\n- The authors provide a clear and concise overview of the problem and its implications, making the paper accessible and easy to understand.\n- The proposed method, utilizing a semi-supervised approach with a student-teacher framework, is innovative and shows promise in achieving better fairness-accuracy trade-offs compared to existing methods.\n- The empirical results are comprehensive and convincingly demonstrate the effectiveness of the proposed method across multiple datasets.\n- The paper is well-structured and logically organized, which enhances its readability and comprehension.\n\n**Weaknesses**\n- The novelty of the proposed method is questioned due to the significant overlap with existing fairness-enhancing methods, such as FairDA and FairFS. The paper lacks a clear differentiation from these methods.\n- The assumption that ground truth sensitive attributes are available for training the sensitive attribute classifier may not be practical or realistic, limiting the applicability of the proposed method in real-world scenarios.\n- The methodology for determining the uncertainty threshold is not well-articulated, which is crucial for the practical implementation of the proposed method.\n- The paper does not adequately address the issue of proxy-sensitive attributes, which is a significant concern when sensitive attributes are partially missing.\n- The paper's focus on a specific demographic scarce regime may limit its relevance and applicability to broader scenarios in machine learning fairness.\n- The experimental setup is somewhat constrained, using only five datasets, which may not sufficiently validate the robustness and generalizability of the proposed method.\n\n**Questions**\n- Could the authors elaborate on how the proposed method differs from existing methods like FairDA and FairFS in terms of technical implementation and theoretical contributions?\n- What are the specific advantages of using the proposed method over existing approaches, particularly when ground truth sensitive attributes are not available?\n- Can the authors provide a more detailed explanation of the methodology used to determine the uncertainty threshold, particularly in scenarios where there is no ground truth available?\n- How does the proposed method handle scenarios where the sensitive attribute classifier fails to predict sensitive attributes with sufficient confidence, and what are the implications for fairness and accuracy?\n- Could the authors discuss the potential applicability of the proposed method to broader scenarios in machine learning fairness beyond the demographic scarce regime?\n- In light of the experimental results, could the authors provide more insights into the performance of the proposed method under different conditions, such as varying levels of missing sensitive attributes?"
    },
    "PtB6l1vNtk": {
        "gold_review": "**Summary**\nThe paper introduces a novel deep learning method using a graph convolutional network to predict Lagrangian multipliers for solving mixed integer linear programs (MILPs), which are typically NP-hard. This method is tested on specific MILP problems like multi-commodity fixed-charge network design and capacitated facility location, achieving promising results by closing significant gaps between continuous and optimal Lagrangian relaxations. The approach departs from traditional iterative algorithms, enhancing computational efficiency by leveraging predefined solutions from simpler problems as training data. Despite its innovative approach and technical soundness, the paper is critiqued for its lack of comparison with existing methods and reliance on self-generated datasets, raising concerns about generalizability and robustness. Reviewers are also concerned about the paper's narrow focus on specific MILP problems, which might limit the broader applicability of the proposed solution. Overall, while the paper presents a potentially industry-valuable strategy, its limited experimental validation and comparisons with baseline methods present significant drawbacks.\n\n**Strengths**\n- The proposed method demonstrates good generalization from training to testing datasets, offering effective predictions even with small datasets.\n- The approach soundly utilizes the Lagrangian dual to provide good lower bounds, which is an improvement over previous results in solving MILPs.\n- The framework accommodates variable input sizes and tests on relevant MILP problems, indicating a level of practical applicability.\n- The learned solutions can effectively warm-start bundle methods, potentially reducing computation times.\n- The deep learning architecture, while combining known techniques, presents a novel approach to predicting Lagrangian multipliers.\n- The method is more general compared to previous methods for predicting optimal Lagrange multipliers, indicating potential for broader impact in combinatorial optimization.\n\n**Weaknesses**\n- The paper lacks experimental comparison with other methods, which is critical for validating the claimed improvements and understanding its position within the field.\n- There is no citation of significant related works, such as those involving encoder-decoder refinements in training, which is a substantial gap in the literature review.\n- Experiments are conducted only on self-generated datasets, limiting the external validity and transparency of the results.\n- It remains unclear how beneficial the approach is compared to traditional integer programming solvers like Gurobi, as comprehensive runtime comparisons are missing.\n- Some technical contributions appear limited, with primary techniques already existing in the literature, contributing only incrementally to the field.\n- The problem instances used (MCDN, CFL) are somewhat specialized; more general and common MILPs should also have been tested to better assess the approach\u2019s applicability.\n\n**Questions**\n- Can you define the CR bound in your paper's context and clarify how the learned dual solution compares with the CR dual solution in terms of GAP and GAP-CR?\n- What was the inclusion of the bundle method warm-start and does this time accounting include the CR/DNN forward time?\n- How does the proposed approach perform against Gurobi in solving the MILP instances?\n- How competitively does the approach predict multipliers compared to simpler models like k-NN or other learning-based methods for Lagrangian dual variables?\n- Is there an explanation on how the method handles training without needing coefficients of the variables in MILP constraints which typically vary widely?\n- Are there plans to make the code and datasets available should the paper be accepted, to enable reproducibility and further research by others?",
        "inference_review": "**Summary**\nThe paper introduces a deep learning approach for predicting Lagrangian multipliers in Mixed Integer Linear Programming (MILP) to enhance Lagrangian relaxation bounds. It employs a graph convolutional network (GCN) to encode the MILP constraints, followed by a decoder that transforms these representations into Lagrangian multipliers. The method was evaluated using a small dataset of 40 instances, showing promising results, but there are concerns about the novelty and the dataset size. The approach involves training a model to predict Lagrangian multipliers, which is then used to improve the Lagrangian bounds. While the idea of using machine learning to enhance the Lagrangian relaxation bounds is not new, the application of GCNs to predict Lagrangian multipliers is novel. However, the paper lacks in-depth theoretical analysis and comprehensive experimental results, including comparisons with existing methods and larger datasets.\n\n**Strengths**\n- The paper introduces a novel method using graph convolutional networks to predict Lagrangian multipliers, which is a unique approach in this field.\n- The research addresses the significant and practical problem of improving the Lagrangian relaxation bounds in Mixed Integer Linear Programming (MILP).\n- The paper is well-written, making it easy to understand the methodology and results, and the experiments are thoroughly described.\n- The proposed method demonstrates strong empirical results, showing that the Lagrangian bound can be significantly improved, which is essential for solving MILP problems.\n- The idea of using machine learning to enhance the Lagrangian relaxation bounds is novel and could inspire further research in this area.\n\n**Weaknesses**\n- The dataset used is small, consisting of only 40 instances, which raises concerns about the generalizability and reliability of the results.\n- The paper lacks a comprehensive theoretical analysis, such as proving the convergence of the Lagrangian multiplier prediction algorithm.\n- There is a significant gap in the literature review, particularly in the discussion of related works that use machine learning for Lagrangian relaxation bounds.\n- The experimental results are not thoroughly compared with other existing methods, and the paper does not provide enough information about the experimental setup and the computational cost.\n- The paper has several typos and unclear figures, which could affect the understanding of the methodology and results.\n\n**Questions**\n- How does the proposed method compare to other existing methods in terms of prediction accuracy and computational cost?\n- Could you provide a more detailed explanation of the graph convolutional network used in the proposed method?\n- How is the Lagrangian relaxation bound used to train the prediction model, and is there a specific algorithm used for this purpose?\n- How does the Lagrangian bound improve with the proposed method, and are there any theoretical guarantees for the convergence of the Lagrangian multiplier prediction algorithm?\n- Why was the dataset chosen as small as 40 instances, and can you provide more details about the experimental setup and the computational cost involved?"
    },
    "xJ5N8qrEPl": {
        "gold_review": "**Summary**\nThis research presents a new single-loop Hessian-free algorithm for bi-level optimization (BLO) problems involving lower-level (LL) constraints coupling both upper and lower-level variables. This innovative approach utilizes the Moreau envelope value function, enabling a single-level reformulation with smooth constraints. This results in the proposed Lagrangian Value function-based Hessian-free Bi-level Algorithm (LV-HBA), which relaxes the strongly convex assumption on the lower-level problem to general convexity. The paper provides a detailed non-asymptotic convergence analysis and validates the effectiveness of the algorithm through extensive numerical experiments across various practical applications, highlighting its superior performance and computational efficiency.\n\n**Strengths**\n- The paper is well-written, with clear organization and elucidation of assumptions, which makes it easy to follow and understand both the primary concepts and the technical intricacies of the proposed approach.\n- The paper introduces the first single-loop Hessian-free algorithm for solving the bilevel optimization (BLO) problem, which includes a novel use of the Moreau envelope value function leading to an efficient gradient-based algorithm.\n- A new potential function associated with monotonically decreasing step sizes is presented, and methods to select these step sizes to ensure sufficient descent are demonstrated.\n- The authors include non-asymptotic convergence analysis for the proposed method and relax the lower level problem's requirements from strongly to only convex, increasing the method's applicability.\n- Extensive experimental results on five machine learning tasks validate the performance and demonstrate the efficiency of the proposed methods.\n\n**Weaknesses**\n- The paper includes many hyperparameters, which complicates practical implementation and parameter selection.\n- Some of the assumptions such as Assumption 3.1(i) and 3.3(ii) are considered too strong or unclear, which might limit the applicability of the proposed method in practical scenarios where these conditions are not met.\n- Comparisons with some recent significant works in constrained BLO through the value function approach are missing, which could provide a deeper contextual understanding of the paper's position within current research.\n- It is unclear whether the performance of the algorithm is overly sensitive to the stepsize parameters, and the choice of certain parameters like 'r' for the truncated proximal Lagrangian value function is not discussed.\n- The paper could benefit from more examples of bilevel optimization in machine learning with non-smooth and weakly convex lower level functions to better motivate and illustrate the approach.\n\n**Questions**\n- 1. Can the authors elaborate on why there is no need to assume Lipschitz continuity of the upper-level function F(x,y), which is typically necessary in bilevel optimization?\n- 2. How is the exact form of \u03c1f determined, especially in practical applications where it is potentially smaller than Lf?\n- 3. Can the authors clarify whether the optimal solutions of the reformulated and the original constrained BLO problem are equivalent, as suggested by Theorem A.1?\n- 4. How should the parameter 'r' be chosen in practical applications as mentioned in reformulation (5)?\n- 5. Could the authors provide insights into the central benefit of using the Moreau envelope as opposed to the optimal value function in the technical aspects of this work?\n- 6. How are the hyperparameters, including 'r', chosen in the experimental setups, and what guidance can the authors provide for their selection in practice?",
        "inference_review": "**Summary**\nThis paper introduces a novel Hessian-free algorithm, termed LV-HBA, designed for solving constrained Bi-Level Optimization (BLO) problems. The algorithm employs a proximal Lagrangian value function to handle constrained lower-level problems, converting them into a single-level optimization problem. LV-HBA does not require strong convexity of the lower-level problem and is capable of handling non-singleton scenarios. The convergence of LV-HBA is analyzed under specific assumptions, and the paper also includes experimental results that validate the practical performance of the algorithm. However, the paper's novelty and the significance of the improvements over existing methods are questioned, with concerns raised about the clarity and organization of the presentation.\n\n**Strengths**\n- The paper is well-written and easy to follow, which facilitates understanding of the content.\n- The proposed method is described as novel and simple to implement, which could enhance its adoption in practical scenarios.\n- The authors have provided a thorough convergence analysis and have conducted experiments that support the algorithm's practical effectiveness.\n- The paper introduces a novel approach using a proximal Lagrangian value function, which simplifies the problem formulation and enables the development of a Hessian-free gradient-based algorithm.\n- The use of a proximal Lagrangian value function to handle the constrained lower-level problem is an interesting and innovative approach.\n\n**Weaknesses**\n- The paper lacks a detailed discussion of the convergence analysis, particularly concerning the assumptions and their impact on the results.\n- The novelty of the proposed algorithm is questioned, as it appears to be an extension of previous works with limited new contributions.\n- There is a significant overlap between the proposed algorithm and existing methods such as those in Liu et al. (2023), making it difficult to discern the new contributions.\n- The paper does not address the practical implementation of the algorithm, particularly how to handle constraints in a real-world setting.\n- The performance of the algorithm is only compared with a single existing method (GAM), which does not provide a comprehensive evaluation of its effectiveness.\n- The clarity and organization of the paper are concerns, as some sections (e.g., Section 4.2) are difficult to follow, and the use of notation and terminology is inconsistent.\n- The motivation for using a proximal Lagrangian value function is unclear, and its specific advantages over other methods are not well-explained.\n\n**Questions**\n- 1. Can the authors clarify the assumptions made in the convergence analysis and explain their impact on the results?\n- 2. What are the main differences between the proposed algorithm and existing methods, and what new contributions does this paper make?\n- 3. How does the algorithm handle constraints in practical scenarios? Is there a need for additional assumptions or modifications to the algorithm?\n- 4. Could the authors provide more detailed experimental results, including comparisons with other existing methods, to better evaluate the performance of the algorithm?\n- 5. In Section 4.2, the authors mention that the algorithm has a single-loop structure. Can this be clarified, and is there a specific advantage of this structure?\n- 6. The paper uses a proximal Lagrangian value function, but it is unclear how this approach differs from or improves upon other methods. Can the authors provide more details on this?\n- 7. There are several notation and terminology inconsistencies throughout the paper. Could the authors clarify these and ensure consistency throughout the document?"
    },
    "You77eOFDv": {
        "gold_review": "**Summary**\nThe paper introduces a novel technique termed Re-parameterized Refocusing Convolution (RefConv), which enhances pre-trained models' performance without incurring additional inference costs. It does this by re-orienting convolution kernels to focus on novel representations. The approach involves incorporating additional learnable parameters during training that merge with the model\u2019s original parameters during inference. Despite evidence of improved effectiveness in several classic convolutional networks, concerns arose from limited validations against modern architectures and stronger baselines. Questions regarding iterative improvements and the genuine necessity of linking channel information remain inadequately addressed. The paper's effectiveness, especially in its validation against widely-acknowledged benchmarks and datasets like ImageNet, was a central point of contention among reviewers.\n\n**Strengths**\n- The approach in this paper is innovative, described as \"convolution B of convolution A\", where convolution A is pre-trained and kept frozen while convolution B continues to train.\n- The method demonstrates a slight advantage over several other structural reparameterization and weight reparameterization methods, supporting the claim that reparameterized refocusing reduces channel redundancy.\n- The paper includes a variety of experiments using different convolutional models which demonstrates the method's versatility.\n- The paper effectively utilizes visual aids, such as Figure 1, which clearly and effectively conveys the central concepts, and employs various visualization techniques to provide valuable insights.\n- There are no additional costs during the inference phase due to the seamless integration of parameters, which is beneficial from a practical standpoint.\n\n**Weaknesses**\n- Although there is about a 1% performance improvement on models like ResNet, DenseNet, and MobileNet, the solution introduces significantly more parameters, potentially compromising model efficiency.\n- The paper lacks experimental results on newer convolutional architectures such as SlaK, RepLKNet, and HorNet, which raises questions about the method's effectiveness on modern neural networks.\n- There is a higher computational cost noted during training without clear validation of the accuracy or reliability of this process, raising concerns about the practicality of the method.\n- The data from ImageNet, specifically in the experimental results shown in Table 1, is questioned for its accuracy and validity. The review suggests the data does not align well with data from standardized libraries such as timm.\n- The method's effectiveness is questioned under standard training procedures. It implies that it might only present advantages under specific, perhaps less optimal, training conditions.\n- The method is criticized for potentially being akin to providing more extensive training to an initially under-trained model, thereby questioning the necessity of the method if models are trained adequately by standard methods.\n\n**Questions**\n- Can the refocusing technique be iteratively applied multiple times, and if so, does it continue to improve results or reach a plateau?\n- What is the necessity and impact of possibly linking individual channels of the base weight (W_b), given each channel's specific role?\n- During the refocus training, is there any evidence from experiments on other models, especially newer convolution models, to suggest whether this approach degrades performance when compared to the original model's performance?\n- The authors are questioned on how accurately they incorporate results from iterative refocusing in their models and whether these align with advanced training practices like those provided in scholarly resources like timm?",
        "inference_review": "**Summary**\nThe paper introduces a novel technique named Re-parameterized Refocusing Convolution (RefConv) which aims to enhance the performance of Convolutional Neural Networks (CNNs) by reparameterizing existing convolution layers. This method involves applying a trainable Refocusing Transformation to the basis kernels of the convolution layers to create new connections among the parameters. The technique is demonstrated to improve performance on image classification tasks, object detection, and semantic segmentation without additional computational costs or altering the original model structure. Experimental results indicate that RefConv can boost the accuracy of various CNN architectures, though the novelty and the incremental value over existing methods remain questionable. The paper also explores the theoretical underpinnings of this technique by analyzing the loss landscape and the channel redundancy reduction, but these aspects are underdeveloped and require further clarification.\n\n**Strengths**\n- The proposed RefConv technique is well-motivated, aiming to enhance the representational capacity of pre-trained models by establishing connections among the parameters of convolution kernels.\n- Extensive experiments demonstrate that RefConv improves the performance of various CNN-based models without introducing additional inference costs or altering the original model structure.\n- The paper is well-written and easy to follow, providing clear explanations of the methods and results.\n- The technique of re-parameterizing the weights of convolutional layers is a novel approach, contributing to the field of neural network optimization.\n- The method is shown to be effective in enhancing the accuracy of different CNN architectures on multiple tasks.\n\n**Weaknesses**\n- The paper lacks a comprehensive comparison with existing methods, which raises questions about the novelty and effectiveness of the proposed technique.\n- The proposed method primarily focuses on convolutional layers, neglecting other essential layers such as pooling layers, which could also benefit from similar re-parameterization techniques.\n- The motivation behind the proposed method is unclear, and the paper does not sufficiently address why the proposed technique should be preferred over simpler alternatives like fine-tuning or re-initializing weights.\n- The paper does not include code or further details about the implementation of RefConv, which could hinder reproducibility and validation by other researchers.\n- The experimental results section is limited to a single dataset (ImageNet), and the paper does not explore how the proposed technique performs across different datasets or under different conditions.\n- The theoretical analysis provided in the paper is not robust enough, particularly in terms of explaining the mechanism behind the performance improvements and the impact of the Refocusing Transformation on the model's behavior.\n\n**Questions**\n- Can the authors clarify the motivation behind the proposed method and provide a more detailed comparison with existing techniques?\n- Why were pooling layers not considered for re-parameterization, and could the proposed method be extended to these layers?\n- How does the proposed method compare to simpler alternatives such as fine-tuning or re-initializing weights, especially in terms of computational efficiency and performance impact?\n- Could the authors provide further details about the implementation of RefConv, including code and a more thorough experimental analysis on multiple datasets?\n- In what ways does the Refocusing Transformation affect the model's behavior, and how does it contribute to the observed performance improvements?"
    },
    "pB1FeRSQxh": {
        "gold_review": "**Summary**\nThe paper presents a quantum algorithm for minimizing the maximum loss of N convex Lipchitz functions. It offers a quantum speedup by leveraging Gibbs sampling in the quantum optimization model with a structured presentation of key ideas, approaches, and bounds. The regularized ball optimization oracle, familiar from classical algorithms, is utilized in a new context providing a quantum advantage. The paper improves upon existing classical algorithms by achieving O~(N * epsilon^-5/3 + epsilon^-8/3) for the complexity, offering a quadratic speedup in terms of dependency on N, though still maintaining a worse dependency on epsilon compared to classical approaches. The paper includes a discussion on the gaps between the upper and lower bounds as an area for further exploration.\n\n**Strengths**\n- The paper presents an improved quantum algorithm for a foundational problem in convex optimization, making significant progress on a well-studied optimization task.\n- The use of quantum Gibbs sampling as a method to enhance the algorithm's performance is particularly interesting and novel.\n- The results reported are clear and informative, and the paper successfully demonstrates that quantum algorithms could potentially outperform classical counterparts under certain conditions.\n- It establishes that the dependence of the number of queries on the number of functions N is optimal up to logarithmic factors, which is a strong contribution to the field.\n- The paper is generally well-written, making it accessible for both quantum and non-quantum audience.\n\n**Weaknesses**\n- There is a notable gap between the upper and lower bounds which is unaddressed, affecting the completeness of the results.\n- The novelty of the algorithm is questionable as it largely entails the incorporation of a known quantum step into an existing classical algorithm framework.\n- The paper could benefit from a more polished presentation, particularly in improving the clarity of the language used which at times appears awkward or unclear.\n- Specific content, such as the presentation of certain equations and references, as well as the naming of elements could be streamlined for clarity and conciseness.\n- While the algorithm is optimal with respect to the number of functions N, it is not optimal concerning the error term (\\u03f5), where known classical algorithms reportedly perform better.\n\n**Questions**\n- Could you clarify the necessity of a rejection sampling procedure following the modifications in the quantum sampling algorithm (Algorithm 2) mentioned?\n- It would be beneficial to elaborate on the reasons for the existing gap between the upper and lower bounds, especially in comparison with classical algorithms.\n- Can you elaborate on how classical algorithms achieve better performance with respect to \\u03f5 and whether a more powerful oracle contributes to this?\n- Is there potential for a meta-theorem that generalizes the quadratic speedup observed in quantum algorithms to a broader class of computational/optimization problems, provided certain conditions are met in the classical algorithms employed?",
        "inference_review": "**Summary**\nThe paper explores the problem of minimizing the maximum of N convex, Lipschitz functions using quantum algorithms, introducing a quantum version of the ball optimization oracle (BROO) and a quantum algorithm that achieves a sub-quadratic query complexity. This quantum approach is compared against classical methods, particularly focusing on the Carmon et al. (2021) algorithm, and demonstrates a possible speedup through quantum means. Despite its novelty, the paper is critiqued for its limited comparison with existing quantum algorithms, its unclear presentation, and an overall lack of substantial experimental or theoretical justification for its claims. The lower bound presented does not clearly exceed the classical complexity of O(N\u03b5^(-2/3)), and the paper's presentation of quantum algorithms and their novelty is questioned.\n\n**Strengths**\n- The paper is clearly motivated and provides a detailed analysis of the lower bound for the problem of minimizing the maximum of N convex, Lipschitz functions, showing that quantum algorithms can be competitive with classical methods.\n- It introduces a quantum version of the ball optimization oracle (BROO) and a quantum algorithm that achieves a sub-quadratic query complexity, demonstrating potential speedup over classical methods.\n- The paper is well-written, making the content accessible and understandable, with a clear presentation of the quantum algorithm and its application to the problem.\n- The problem addressed is of significant interest in the field, highlighting the relevance and importance of the research topic.\n\n**Weaknesses**\n- The paper does not sufficiently compare its quantum algorithm with existing quantum algorithms, such as those presented in [Liu et al. 2022; Gong et al. 2022; Childs et al. 2022; Zhang et al. 2021], which could provide a more comprehensive understanding of its novelty and efficiency.\n- The experimental section is missing, which is crucial to verify the algorithm's performance and to compare it with classical methods.\n- The lower bound presented in the paper does not clearly exceed the classical complexity of O(N\u03b5^(-2/3)), which raises questions about the novelty and significance of the results.\n- The paper lacks a detailed theoretical justification for the quantum algorithm's performance and does not provide a detailed comparison with the classical algorithms mentioned, such as the one by Carmon et al. (2021).\n- The overall presentation of the paper is unclear, with several parts of the manuscript being hard to follow, and the notation used is confusing and not well-explained.\n\n**Questions**\n- Could the authors provide a more detailed comparison with existing quantum algorithms, particularly focusing on the differences and improvements in the proposed quantum algorithm?\n- How does the proposed quantum algorithm compare with the classical algorithm by Carmon et al. (2021) in terms of query complexity and practical performance?\n- Can the authors clarify the experimental section and provide experimental results to validate the claims made in the paper?\n- Could the authors provide a more detailed theoretical justification for the quantum algorithm's performance, specifically how it achieves the claimed speedup over classical methods?\n- Is there a possibility to expand on the theoretical comparison with classical algorithms and provide more rigorous mathematical justification for the results?\n- Can the authors clarify the notation used in the paper and provide a more detailed explanation of the quantum algorithm's components, particularly the quantum sampling subroutine and the quantum gradient estimation method?"
    },
    "Ue93J8VV3W": {
        "gold_review": "**Summary**\nThe paper introduces eight graph datasets each containing 7-31 features per node and evaluates various machine learning models against these benchmarks, focusing on heterogeneous node features. Named 'TabGraph', the benchmarks provide a mix of feature types, node numbers, average degrees, and domains. The paper discusses the implementation of models like GNNs, tabular deep learning, and tree models, alongside a hybrid approach. Various recommendations and analyses are given for both tabular and graph machine learning fields. The contribution centers around bridging the gap between traditional tabular data modeling and newer graph-based machine learning techniques. However, the paper lacks in-depth theoretical insights and substantial novelty in methodology, bringing into question its authenticity and potential impact on the field.\n\n**Strengths**\n- The new datasets include useful node-level features, especially enriching existing benchmarks with additional attributes that add realism to the graph datasets.\n- The paper provides several benchmark datasets useful for machine learning models focusing on both tabular and graph-based approaches, along with combinations of the two.\n- There are valuable insights and recommendations for researchers and practitioners working with a mix of tabular and graph data.\n- The introduction of performance comparison across various machine learning models for tabular data and graph-based models highlights the applicability in real-world scenarios.\n- The paper effectively fills the gap between machine learning for tabular data and graph machine learning by comprising datasets of different kinds and attempting a comprehensive evaluation of major models.\n- The structure of the paper is commendable, making it a readable and approachable resource.\n\n**Weaknesses**\n- The paper lacks in-depth discussion on the rationale for dataset construction and does not thoroughly analyze the qualitative properties of newly created datasets.\n- There is a significant need for greater insight into the empirical study, which currently only presents results from base models without further analytical discussion.\n- The document does not effectively differentiate between transductive and inductive settings in its analysis, a distinction crucial for the applicability of graph neural networks and graph-based machine learning.\n- The paper's focus and contribution towards \"research\" are weak, leaning more towards being a dataset paper rather than offering significant advancements in graph learning.\n- There are unaddressed limitations, such as the conversion of relational data into graphs, the computational costs associated, and the non-inclusion of certain data types like strings or texts which are crucial in tabular data.\n- The methodology for dataset selection and preprocessing lacks clarity and comprehensiveness.\n- Insights provided are not entirely convincing due to the dataset being preprocessed by undisclosed rules.\n\n**Questions**\n- What was the specific criteria for the selection of these eight tabular datasets?\n- How does the paper address the difference between transductive and inductive learning methods, particularly in performance comparison?\n- Can the authors provide clarity on the comparative model performances on homogeneous features versus heterogeneous features to demonstrate the efficacy of the proposed datasets?\n- Why were strings or text data types not included in TabGraph, and how does this omission affect the benchmarks provided?\n- Could the authors explain their decision-making process regarding which features to include or exclude during dataset preprocessing, such as the number of votes in GBDT experiments?\n- What is the rationale behind the choice of thresholds for different datasets as mentioned in Section 3.1?\n- Is there a plan for adding at least one dataset from the science domain for node classification and regression tasks?\n- Can the importance of different types of features (number, binary, categorical) be comparatively analyzed in the paper?\n- What are the expected dates for the release of the source code and the datasets?\n- Could the authors elaborate on the resource implications of converting tabular data into graphs, considering computational limits and other constraints?",
        "inference_review": "**Summary**\nThe paper presents a benchmark for graph datasets with heterogeneous features, specifically focusing on tabular data. The authors introduce a collection of datasets derived from various sources, including academic and proprietary data, to study graph-structured data with tabular features. The benchmark aims to explore the performance of machine learning models, particularly graph neural networks (GNNs), on these datasets. Key findings indicate that GNNs can outperform traditional methods like decision trees in certain scenarios. However, the paper faces criticism for its limited novelty, unclear motivations, and a lack of comprehensive experimental results. The benchmark, while promising, requires more rigorous testing and validation, particularly across different tasks and model types.\n\n**Strengths**\n- The paper introduces a novel benchmark dataset which can serve as a valuable resource for the community.\n- The paper is clearly written, making it accessible and easy to follow.\n- The benchmark covers a wide range of tabular datasets and evaluates a diverse set of models, including GNNs, providing a comprehensive evaluation of existing methods.\n- The experimental setup is well-structured, enhancing reproducibility and facilitating future research in this area.\n\n**Weaknesses**\n- The novelty of the paper is limited as it primarily combines existing datasets without significant new contributions or insights.\n- The motivation behind the creation of the benchmark is unclear and not well articulated, particularly why tabular data is treated as a graph.\n- The paper lacks a detailed discussion of the challenges and limitations of the benchmark, which is crucial for its utility and adoption by the community.\n- The experimental results are insufficiently detailed, with limited discussion on model performance across different datasets and tasks.\n- There is a lack of comprehensive testing, particularly in terms of the number of runs and the evaluation of hyperparameters, which undermines the reliability of the results.\n- The paper does not adequately address the differences between tabular and graph machine learning, nor does it provide sufficient justification for the focus on GNNs over other models.\n\n**Questions**\n- What motivated the authors to treat tabular data as a graph, and what specific challenges does this approach address?\n- Can the authors clarify the criteria used for selecting datasets and the rationale behind the choice of GNNs over other models?\n- How does the benchmark address the differences between tabular and graph machine learning, and what are the implications for the models evaluated?\n- In terms of experimental setup, could the authors provide more detailed information on the number of runs and the evaluation of hyperparameters?\n- Why were certain datasets excluded from the study, and what are the implications of this exclusion for the benchmark's validity?\n- Could the authors provide more insights into the performance of models across different datasets and tasks, and discuss any notable trends or challenges observed in the experimental results?"
    }
}