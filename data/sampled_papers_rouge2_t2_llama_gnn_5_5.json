{
    "7sMR09VNKU": {
        "gold_review": "**Summary**\nThe paper introduces a method for learning system dynamics from noisy observations by embedding states and controls into a space where the dynamics transition function is linear, with the application of Koopman operator theory (KOT). The primary contribution is a novel methodological framework that integrates optimal control principles with deep neural network-based embeddings to solve nonlinear control problems by translating them into linear representations in a lifted feature space. Experimental validations include simulation experiments on systems like pendulum and cartpole using linear-quadratic regulator (LQR) control design. Despite being well-motivated by challenging real-world control issues, the paper struggles with comparisons against well-established methods, the omission of broader baseline comparisons, and the non-universality of the approach across different system dynamics.\n\n**Strengths**\n- The paper effectively investigates the incorporation of states and controls into a dynamically linear feature space, aiding in the understanding of nonlinear dynamical systems.\n- The authors have executed detailed simulation experiments which validate their method and have provided sufficient details, making it possible for others to replicate these simulations.\n- The writing style of the paper enhances clarity, easing the comprehension of the nuances and contributions for readers.\n- Innovative use of DNNs to learn Koopman embeddings from images, simplifying the process of applying Koopman control while aiding generalization to arbitrary robotic systems.\n- A clear and thorough presentation of the network structure and its components, including the use of \"delayed\" coordinates in LQR, is well-defined, methodologically sound, and beneficial for less familiar audiences.\n- The paper includes a comprehensive section on related work, aiding in establishing the context and relevance of the research.\n\n**Weaknesses**\n- A significant limitation is noted in the computational challenge associated with solving the LQR, which may become overly costly for high-dimensional systems.\n- The proposed method lacks explicit comparisons with existing methods, particularly established control techniques like Nonlinear MPC, iLQR, PID, and others.\n- The applicability of the Koopman operator theory (KOT) presented is restricted primarily to control-affine systems, which limits its generalizability to various nonlinear systems that do not follow the control-affine form.\n- There seems to be an insufficient engagement with contemporary literature, especially with existing contributions around stability using Koopman-based learned matrices.\n- Research scope in demonstrations is narrow; primarily simple systems such as pendulums and cartpoles are considered, casting doubt on the method's generalizability and effectiveness on more complex or practical systems.\n- The paper's experiments section is relatively weak and limited, highlighting a dependency on having optimal trajectories for training, which risks undermining the approach's general applicability and novelty.\n\n**Questions**\n- Can the authors provide more detailed comparative studies with existing approaches to better highlight the advantages or improvements of the proposed method?\n- Would it be possible to include demonstrations on more general nonlinear examples, such as quadrotors, Vanderpol oscillators, or vehicle dynamics based on the bicycle model?\n- How is the approximation through Koopman-based lifted space justified for general nonlinear systems as described in the paper, particularly for systems that are not \"control-affine\"?\n- There are concerns about the plots in Figure 5 for the cartpole. Could you clarify if the control for this system is indeed the torque at the base of the pole and explicitly note any deviations from the classic cartpole setup?\n- What justifies the use of the proximal method of multipliers for solving the least squares problem in equation 6 over more conventional methods like iterative refinement?\n- How are the parameters M and T determined in your experiments, and what guidelines can you provide regarding their settings in practice?",
        "inference_review": "**Summary**\nThe paper introduces a method to learn the dynamics of nonlinear systems from sensory input, focusing on a Koopman operator-based approach. It proposes a novel embedding of both states and controls into a feature space where the dynamics are linear, and incorporates a differentiable optimal control problem in the learning objective. The method is validated through simulation experiments involving pendulum and cartpole systems, demonstrating the effectiveness of the learned model in state prediction and control. However, the paper is criticized for its lack of novelty, inadequate comparison with existing methods, and insufficient theoretical grounding. The reviewers highlighted the need for more comprehensive comparisons with established techniques and a deeper exploration of the theoretical underpinnings of the proposed approach.\n\n**Strengths**\n- The paper introduces a novel method that combines learning the dynamics of nonlinear systems from sensory input with the use of a Koopman operator-based approach, which is both novel and well-motivated.\n- The approach leverages the Koopman operator to construct a linear representation of nonlinear dynamics, which is a significant contribution to the field.\n- The paper is well-written, clear, and easy to follow, with a logical structure that aids in understanding the complex methods and results presented.\n- The method's ability to predict the state of the system accurately and its application to control tasks demonstrate practical relevance and utility.\n\n**Weaknesses**\n- The paper lacks a clear and concise summary of the proposed method, making it difficult for readers to grasp the overall approach and its significance.\n- There is a notable lack of comparison with existing methods, particularly those that also utilize the Koopman operator, which weakens the paper's ability to position itself within the current research landscape.\n- The paper does not provide sufficient theoretical justification for the proposed method, particularly concerning the linearity of the dynamics in the learned feature space.\n- The paper does not include a detailed analysis of the approximation error associated with the learned dynamics, which is crucial for understanding the limitations and robustness of the proposed method.\n- The use of the Koopman operator and the LQR framework is not thoroughly justified, and the paper could benefit from a more detailed discussion on the rationale behind these choices.\n- The experiments are limited in scope and do not convincingly demonstrate the superiority of the proposed method over existing approaches.\n\n**Questions**\n- Can you provide a clear and concise summary of the proposed method, highlighting its main contributions and the novel aspects of your approach?\n- How does the proposed method compare with existing methods that utilize the Koopman operator, particularly in terms of accuracy and computational efficiency?\n- Could you provide a more detailed theoretical justification for the linearity of the dynamics in the learned feature space, and discuss the implications of this linearity on the model's performance?\n- What is the approximation error associated with the learned dynamics, and how does this affect the overall performance and robustness of the method?\n- Why were the Koopman operator and the LQR framework chosen for this study, and how do these choices impact the effectiveness of the proposed method?\n- Could you elaborate on the experimental setup and the choice of baselines used in your study? How do these choices support the validity of your results, and what are the implications of these choices on the overall conclusions of your study?"
    },
    "BOm1RYdHHu": {
        "gold_review": "**Summary**\nThe paper introduces SAFHE (Secure Aggregation with Fully Homomorphic Encryption), a novel framework aimed at defending against both backdoor attacks and gradient inversion attacks in Federated Learning (FL). The approach cleverly utilizes fully homomorphic encryption to ensure that plaintext gradient updates or decryption keys remain concealed, thus safeguarding against unauthorized gradient reconstruction. Furthermore, the proposed system employs a mechanism to reject anomalously large weight updates\u2014a common indicator of backdoor attacks. The technique involves a continuous polynomial approximation (using Chebyshev polynomials) to filter gradient updates effectively within the encrypted domain, potentially enhancing the security of FL systems. In their evaluation, the authors demonstrate the theoretical applicability of their method in typical FL setups, though not without acknowledging certain assumptions and limitations in their experimental approach.\n\n**Strengths**\n- The paper proposes a clear, innovative concept by introducing a weighting function capable of accepting or rejecting client updates within a Federated Learning (FL) environment, operational in a Fully Homomorphic Encryption (FHE) setting.\n- The manuscript is well-written, facilitating a good understanding of the proposed ideas and methodologies for readers.\n- A detailed simulation study has been conducted, showcasing the application and impact of the proposed scheme.\n- The approximation methods through Chebyshev and Taylor series for non-polynomial continuous functions within the FHE context are correctly used.\n\n**Weaknesses**\n- The paper lacks theoretical support for the security and privacy aspects of the proposed scheme, particularly missing security proofs or detailed discussions on privacy guarantees.\n- There are some technical inaccuracies and presentation issues, such as inconsistencies in figures (e.g., Figure 2) and a mismatch between the title and main content focus.\n- The practical implementation and broader applicability of the proposed scheme appear to be oversimplified or not fully addressed, leading to an incomplete evaluation of its effectiveness in real-world scenarios.\n- The paper does not experimentally compare its approximation techniques (like using Chebyshev polynomials for the clip function) with other schemes or discuss in-depth variations and optimizations (e.g., polynomial degrees, parameters a,b,c,d) that could affect performance and security in FL environments.\n- The methodological contributions are questioned regarding their novelty and depth, as some techniques such as using sigmoids for clip functions are considered standard.\n\n**Questions**\n- Can the authors clarify whether the proposed scheme supports a malicious threat model, or detail its behavior under different security threats such as gradient inversion and backdoor attacks?\n- Regarding the technical aspects of your FHE implementation: Can the full computation of the function H and the l2-norm weight of a real gradient from your network be detailed in terms of precision and computational timing?\n- What specific values of parameters like 'c' were utilized in your experiments, and can you provide an ablation study with different values for these parameters?\n- How do the authors address the potential issue of adversaries optimizing their gradient updates to remain undetected (e.g., small yet malicious gradients), or the challenges posed by benign but statistically atypical gradients?\n- Is it possible to run additional experiments on a wider variety of datasets and FL models to better understand the robustness and generality of your approach?\n- Lastly, could the authors include more materials or references to better explain the application and limitations of FHE in preventing gradient inversion attacks, especially for reviewers less familiar with these concepts?",
        "inference_review": "**Summary**\nThe paper introduces a novel secure aggregation scheme for Federated Learning (FL) that utilizes Fully Homomorphic Encryption (FHE) to defend against backdoor attacks and gradient inversion attacks. The method, called SAFHE, employs Chebyshev and Minimax polynomial approximations to weigh client updates based on their magnitude, effectively preventing malicious clients from manipulating the model. The approach ensures privacy by using FHE, which allows for secure aggregation without decrypting client data. The paper provides an empirical evaluation of this method on the CIFAR-10 dataset, showing its effectiveness in mitigating attacks. However, the method's practicality is questioned due to its computational overhead and limited evaluation on other datasets or more complex models.\n\n**Strengths**\n- The paper addresses an important and timely problem of privacy attacks in federated learning (FL) and provides a novel approach by leveraging Chebyshev and Minimax polynomial approximations to defend against such attacks.\n- The use of fully homomorphic encryption (FHE) and secure aggregation methods in FL is innovative and contributes to enhancing privacy and security in FL systems.\n- The paper is well-written, clear, and easy to follow, with a good introduction and related work section that provides context and motivation for the study.\n- The method is theoretically sound and well-explained, including a thorough analysis of the trade-offs between different polynomial approximations and their impact on computational efficiency and model accuracy.\n\n**Weaknesses**\n- The paper's experiments are limited to a small-scale FL setting with only 10 clients and a small dataset (CIFAR-10), which may not convincingly demonstrate the scalability and effectiveness of the proposed method in more realistic or larger FL settings.\n- The computational overhead introduced by the use of FHE is substantial, which may limit the practical applicability of the proposed method, especially in resource-constrained environments.\n- The method relies on a specific type of attack (i.e., ill-formed gradients) and does not account for other types of attacks, such as model poisoning or Byzantine attacks, which could undermine the effectiveness of the defense.\n- The paper lacks a comprehensive comparison with existing methods, particularly those that use other cryptographic techniques like secure multi-party computation (MPC) or zero-knowledge proofs (ZKP).\n- The method's reliance on Chebyshev and Minimax polynomial approximations may not be the most efficient or effective approach, and the choice of these specific methods over others is not adequately justified.\n\n**Questions**\n- Can the authors provide more details on the experimental setup, particularly the choice of number of clients and the dataset used? How do these choices impact the scalability and generalizability of the proposed method?\n- What are the specific computational resources required for the FHE computations, and how do these compare to other methods like MPC or ZKP in terms of efficiency and overhead?\n- How does the proposed method perform against a broader range of attacks, including model poisoning and Byzantine attacks? What are the theoretical or empirical guarantees of the method against these types of attacks?\n- Can the authors provide a more detailed comparison with other existing methods that use different cryptographic techniques? How does the proposed method stack up in terms of effectiveness and efficiency compared to these other approaches?\n- Is there a theoretical justification for choosing Chebyshev and Minimax polynomial approximations over other potential methods? What are the trade-offs involved in using these specific methods, and how do they impact the overall performance of the proposed method?"
    },
    "cXbnGtO0NZ": {
        "gold_review": "**Summary**\nThe paper discusses the generation of 3D graphs through a novel method called \"latent 3D graph diffusion,\" leveraging latent spaces achieved via cascaded 2D-3D graph autoencoders. The approach prioritizes learning a low-error reconstruction and symmetry invariance, which significantly improves the performance of diffusion processes, particularly in generating molecular structures. Both theoretical insights and practical implementations are extensively presented, underpinning the importance of dimensionality and quality of the latent space in enhancing diffusion efficiency and generation quality. The study extensively compares this method against existing ones, demonstrating marked improvements in generation speed and quality, especially in drug discovery contexts.\n\n**Strengths**\n- The paper demonstrates superior generation quality, rapid generation capabilities, and conditional generation proficiency in 3D graph generation, while enhancing robustness through regularization.\n- Well-written, with a straightforward and convincing rationale, supported by multiple numerical experiments showcasing the potential of conditional generation based on various properties.\n- Novel approach and theoretical foundation in addressing the use and implementation of latent spaces in 3D graph diffusion.\n- Innovative use of graph contrastive learning (GCL) to refine and enhance latent space representations for 3D graph autoencoders.\n- High versatility and adaptability of the model, validated through exhaustive evaluation in various scenarios like unconditional and conditional generation on quantum properties and protein targets.\n- Empirical validation showing the proposed method's superiority over existing techniques.\n\n**Weaknesses**\n- Limited generalization capability, emphasizing the need for improvement in diverse application scenarios.\n- Latent space and the necessity of its integration with the 3D graph representation lack detailed explanation and theoretical analysis.\n- Questions regarding the separation and individual influences of topological AE and geometric AE, as well as their integration challenges.\n- Some novelty concerns, as the work leverages existing 3D molecule generation setups with known concepts, potentially limiting groundbreaking contributions.\n- Lack of detailed experiments or ablation studies on the architectural decisions, particularly the difference between one-shot and cascaded AE, which could provide critical insights into their effectiveness and implementation.\n- The paper omits certain critical results and comparisons that could enhance the robustness of its conclusions, for instance, the comparison against more recent or advanced models like MIDI and another baseline refinement for fair comparison.\n- Issues in manuscript details, such as omission errors and unclear proofs, which could affect the readability and interpretability of findings.\n\n**Questions**\n- How can the generalization capability of the model be improved?\n- Could the authors clarify the specific influences of topological AE versus geometric AE and their integration method?\n- What innovations does the cascaded AE bring to the table when compared to traditional one-shot AE?\n- Can the effect of excluding latent space encoding be elaborated upon through an ablation study?\n- The decision behind selecting the Autoencoder (AE) baselines and the performance analysis involving newer models like MIDI should be explained.\n- Regarding the computational cost of AE training, specifically under the conditions of permutation and SE3 invariance, how does this impact the overall model performance and training time efficiency?\n- Further insights would be beneficial on how the model ensures low dimensionality, low reconstruction error, and preservation of group symmetry in the latent space.\n- How might the authors address the absence of results for \"Ours-GSSL\" in unconditional 3D molecular generation, and could they provide further statistical validation or comparative study for the same?",
        "inference_review": "**Summary**\nThis paper introduces a novel method for generating 3D graphs using latent diffusion models, focusing on the latent space to preserve symmetry and improve performance. The proposed method leverages a 2D-3D autoencoder to transform the 3D graphs into a latent space, which is then used for diffusion. The method is applied to drug design, where the latent space is used to generate molecules that are both valid and stable, demonstrating significant improvements over existing methods in terms of efficiency and quality. The paper is well-structured, and the experiments are comprehensive, showcasing the effectiveness of the approach. However, there are concerns about the generalizability of the method, its scalability, and the clarity of certain sections, particularly the methodological descriptions.\n\n**Strengths**\n- The paper introduces a novel approach to generate 3D molecules by leveraging a latent diffusion model, which is a unique and innovative application in the field.\n- The method is described as being well-structured, making it easy to follow, and the experimental results are comprehensive, showing the effectiveness of the proposed approach.\n- The paper addresses an important problem in the field, particularly in the context of drug design, where the ability to generate stable and valid molecules is crucial.\n- The proposed latent diffusion model is effective in generating 3D molecules of higher validity and drug-likeness, with comparable conformations and energetics, and the method is significantly faster than existing methods.\n- The manuscript is well-written, with clear explanations and good overall presentation quality.\n\n**Weaknesses**\n- The paper lacks a detailed description of the 2D-3D autoencoder architecture used for transforming 3D graphs into a latent space, which is crucial for reproducibility and understanding the method's effectiveness.\n- There is a significant concern regarding the scalability of the proposed method. As the size of the molecule increases, the method's efficiency and effectiveness may degrade.\n- The generalizability of the method is a major concern. The paper does not adequately address whether the method can generalize well to different types of molecules, such as those with different numbers of atoms or varying properties.\n- The paper has some inconsistencies in its methodology and presentation. For instance, the paper claims that the method generates molecules that are invariant to SE(3) transformations, but this is not consistently demonstrated throughout the paper.\n- The comparison with other methods in the paper is not comprehensive, and the paper does not include a detailed discussion on the advantages and limitations of the proposed method compared to existing methods.\n\n**Questions**\n- Could you elaborate on the architecture of the 2D-3D autoencoder used in your method? This would help in understanding how the 3D graphs are transformed into a latent space.\n- How does the method perform on molecules with different sizes or varying properties? What is the generalization capability of the method?\n- Can you provide more details on how the latent diffusion model is trained and validated? How does the method handle the trade-off between reconstruction quality and latent space dimensionality?\n- In the results section, could you clarify the meaning of the \"validness\" metric and the values reported in Table 3? How do these relate to the overall performance and quality of the generated molecules?\n- How does the method handle the complexity and variability of real-world molecular structures? What are the limitations of the method in terms of its scalability and adaptability to different types of molecules?"
    },
    "Gny0PVtKz2": {
        "gold_review": "**Summary**\nThe paper introduces ConvFormer, a modification of the Transformer model using convolutional layers to address specific needs in sequential user modeling for recommender systems. Highlighting the limitations of self-attention in handling order sensitivity, maintaining a large receptive field, and ensuring a lightweight model, the authors argue for the superiority of simpler, alternative strategies. ConvFormer is proposed based on these criteria, showing consistent performance gains across benchmark datasets. Despite its strengths, the paper has been criticized for poor integration with the latest advancements, lack of clarity in experimental design, and a somewhat contradictory methodology. Some experiments lacked important baselines, and no online real-time experiments were conducted, obscuring its efficacy in practical scenarios.\n\n**Strengths**\n- The paper identifies the problem of self-attentive transformers when applied in user modeling and demonstrates consistent performance gains on most benchmark datasets.\n- The topic of finding alternatives to the self-attention mechanism is interesting and important, viewed as a good overview of the related literature.\n- The work contains a lot of empirical studies that allow greater granularity in analyzing the sequential learning process.\n- The idea of replacing self-attention with convolutional mechanisms has the potential to become a valuable contribution to the field.\n\n**Weaknesses**\n- The proposed method seems to be behind the recent progress in the machine learning community with outdated formulations.\n- The insufficient literature review does not address several existing advanced methodologies, and there are citations missing at crucial points in the paper.\n- The main experimental descriptions lack clarity, and the design of experiments and the methodology appear contradictory to the main claims of the paper.\n- Some straightforward baselines are missing from comparisons, which makes conclusions on superiority less convincing.\n- The paper does not include online real experiments, and only the ID feature was considered, limiting the generalizability of the findings.\n- There's no clear explanation of how the sequential order is taken into account, and how the causal structure of learning is preserved to avoid data leakage.\n- Computational aspects, such as the handling of long sequences and the impact of different loss functions on model comparisons, are not adequately addressed.\n\n**Questions**\n- 1. What's the relationship between the optimal kernel size (K) and the dataset sequence length?\n- 2. How would you choose the input sequence length?\n- 3. Will adding more blocks improve performance?\n- 4. Can you explain how the proposed modifications ensure the preservation of the sequential order, especially in aspects where contradictions are noted in the descriptions of models like SAR-O, SAR-P, and SAR-R?\n- 5. Could you provide a more detailed justification and expansion on the use of convolutional mechanisms as an alternative to self-attention specifically pertaining to their effectiveness in handling sequential data?\n- 6. Can the experimental scheme be modified to eliminate \"recommendations from the future\" leaks to verify the claimed superiority of the proposed model modifications?\n- 7. How does the proposed model account for different sequence lengths in practical applications like recommender systems where sequence lengths can vary significantly?",
        "inference_review": "**Summary**\nThe paper presents ConvFormer, a modified Transformer architecture designed for sequential user modeling, which aims to enhance the accuracy of next-item predictions by improving token mixers. The proposed ConvFormer leverages a large receptive field and lightweight architecture, while addressing the order sensitivity of items through a novel approach. The paper is supported by experiments conducted on four public datasets, which demonstrate that ConvFormer can outperform various baseline models in terms of ranking metrics. Additionally, the paper introduces an accelerated version, ConvFormer-F, which utilizes Fourier convolution to enhance efficiency. However, the paper faces criticism for its limited novelty, as the convolutional token mixer has been previously explored, and the paper lacks rigorous ablation studies to substantiate the proposed criteria.\n\n**Strengths**\n- The paper is well-written and easy to follow, with a clear presentation of the method and results.\n- The proposed ConvFormer outperforms the baseline models in terms of ranking metrics and is particularly effective on long sequences.\n- The paper identifies and addresses three criteria for designing effective token mixers in sequential user models, which can be valuable for future research.\n- ConvFormer, the proposed model, is simple yet effective and does not require significant modifications to existing architectures.\n- The paper introduces a Fourier acceleration technique that improves the efficiency of ConvFormer-F, especially for long sequences.\n\n**Weaknesses**\n- The novelty of the paper is limited, as the convolutional token mixer has been previously explored, and the proposed modifications to the Transformer architecture are incremental.\n- The paper lacks rigorous ablation studies to substantiate the proposed criteria, which could have strengthened the argument and provided more convincing evidence.\n- The paper does not compare ConvFormer with other models that use a convolutional token mixer, which could have provided a more comprehensive evaluation of the proposed method.\n- The methodological approach and theoretical grounding of the paper are unclear, particularly the justification for the criteria used to design the token mixer.\n- The paper does not provide any theoretical analysis or proof that the proposed criteria are optimal or necessary for the task at hand.\n- The paper lacks a detailed discussion of related works and does not clearly define the key concepts and terms used in the study.\n\n**Questions**\n- Can you provide a more detailed explanation of the criteria used to design the token mixer and how these criteria were determined?\n- Why is the Fourier acceleration technique only applied to ConvFormer-F and not to the original ConvFormer?\n- Can you clarify the differences between the proposed ConvFormer and other existing models that use a convolutional token mixer?\n- How does the proposed model compare to other models in terms of accuracy and efficiency, and what are the advantages of ConvFormer over these models?\n- Could you provide a more detailed discussion of the methodological approach and theoretical grounding of the paper?\n- What are the limitations of the proposed method, and how can these be addressed in future work?\n- Can you provide a more detailed explanation of the experimental setup and the results, particularly in terms of the performance of ConvFormer compared to other models?"
    },
    "ljVCPV7jK3": {
        "gold_review": "**Summary**\nThe paper under review introduces a method to train fairness-enhancing interventions in environments with incomplete sensitive attributes. This method comprises two primary steps: the prediction of missing sensitive attributes via a student-teacher distillation proxy classifier, followed by a selection process based on the confidence threshold of these predictions. The instances identified with less uncertainty are then used to train the intervention. The approach is validated using several benchmark datasets aimed at assessing fairness. The methodology claims improvements in the fairness-accuracy tradeoff but faces criticism for its novelty and execution. Major concerns include the method's resemblance to basic attribute prediction techniques and an incomplete comparison with existing methods in the literature of fairness under similar constraints.\n\n**Strengths**\n- The paper addresses a critical issue in fairness research, focusing on studying fairness without full access to sensitive attributes, a prevalent and relevant problem in privacy-conscious environments.\n- The experiments are extensive, covering a diverse range of datasets and several classification tasks, and delve into the dynamics between the threshold and the encoding of sensitive information.\n- The research evidences a solid commitment to reproducibility through a detailed and transparent presentation of the experimental setup, datasets, and code availability.\n- The clarity and structure of the writing are commendable, enhancing readability and comprehension of the study.\n- Substantial citations of related works are utilized effectively to contextualize their method within the current literature landscape.\n\n**Weaknesses**\n- The technical novelty appears limited, with major techniques resembling baseline methods slightly enhanced by student-teacher transfer learning and filtering by prediction confidence thresholds.\n- There is a notable absence of comparisons with pertinent literature on fairness without full access to sensitive attributes, despite the existence of several relevant studies.\n- Ethical concerns arise from the methodology of predicting sensitive attributes, which might contravene privacy and legal standards.\n- Statements regarding the superiority of the framework over traditional models trained with access to the true sensitive attribute are not consistently supported across different fairness interventions as analyzed.\n- The method's sensitivity to the uncertainty threshold raises questions about its practical applicability and robustness, given that optimal threshold settings appear to be selected based on testing data rather than a standardized or validated method.\n\n**Questions**\n- Can the authors clarify the specific technical contributions of their methodology beyond the use of proxy classifiers with transfer learning and thresholding predictions?\n- Why were comparisons not drawn with established methods in the domain of fairness without full access to sensitive attributes, such as those outlined in the provided literature?\n- Given the ethical implications of predicting sensitive attributes, could the methodology be adjusted to utilize instances with high uncertainty regarding sensitive information, potentially enhancing ethical acceptability?\n- In practical applications, how would the optimal uncertainty threshold be determined to avoid reliance on trial and error?\n- How do the authors justify the approach's performance claims against interventions using actual sensitive attribute data, especially given variations highlighted in different figures and under varying experimental conditions?",
        "inference_review": "**Summary**\nThe paper explores the use of proxy-sensitive attributes to improve fairness in classification tasks, particularly when true sensitive attributes are missing. It introduces a framework that employs a two-stage approach: first, a sensitive attribute classifier is trained to predict the missing sensitive attributes, and second, a fair classifier is trained with fairness constraints applied only to samples where the sensitive attribute prediction is highly confident. The paper claims that this approach can achieve better fairness-accuracy trade-offs compared to using true sensitive attributes. However, the paper lacks clarity and precision in its methodology and results, with numerous instances of vague descriptions and unexplained experimental choices. Moreover, the paper does not adequately justify the need for proxy-sensitive attributes and fails to sufficiently compare its method to existing works in the field.\n\n**Strengths**\n- The paper addresses an important and relevant topic in fairness in machine learning, particularly focusing on scenarios where sensitive attributes are missing or partially available.\n- The proposed approach integrates uncertainty estimation into the sensitive attribute classifier, which could potentially yield better fairness-accuracy trade-offs.\n- The paper is well-structured and easy to follow, with a clear description of the methodology and the motivation behind the research.\n- The experimental section is robust, providing a comprehensive evaluation of the proposed method against various baselines and datasets.\n\n**Weaknesses**\n- The paper lacks a clear and detailed explanation of the proposed method, particularly how the sensitive attribute classifier and the fair classifier interact and how the fairness constraints are applied.\n- There is a lack of clarity on the utility of the proposed method, specifically the necessity of using proxy-sensitive attributes over true sensitive attributes when available.\n- The paper does not sufficiently compare its method to existing works in the field, particularly those that also utilize proxy-sensitive attributes.\n- There is a concern regarding the reliability of the proxy-sensitive attribute classifier, as the paper does not provide a thorough evaluation of its performance or compare it to existing methods.\n- The paper's experimental results are not adequately discussed, particularly in terms of the fairness-accuracy trade-offs achieved by the proposed method.\n- The methodology and experimental design lack a rigorous theoretical foundation and justification, particularly in terms of the uncertainty estimation and its impact on fairness.\n\n**Questions**\n- Can the authors clarify the role and functionality of the sensitive attribute classifier within the proposed framework? How does it interact with the fair classifier, and how are fairness constraints applied?\n- What is the specific advantage of using proxy-sensitive attributes over true sensitive attributes when available? How does this choice impact the performance and fairness of the model?\n- Could the authors provide more details on the proxy-sensitive attribute classifier's performance and compare it to existing methods to demonstrate its effectiveness?\n- How does the proposed method compare to other fairness-enhancing methods that do not rely on proxy-sensitive attributes? Can the authors provide a more detailed comparison, possibly including a table or figure that highlights the differences?\n- Given the concerns about the reliability of the proxy-sensitive attribute classifier, can the authors provide additional experimental results or analysis to support the effectiveness and robustness of this component?"
    },
    "PtB6l1vNtk": {
        "gold_review": "**Summary**\nThe paper introduces a novel deep learning method using a graph convolutional network to predict Lagrangian multipliers for solving mixed integer linear programs (MILPs), which are typically NP-hard. This method is tested on specific MILP problems like multi-commodity fixed-charge network design and capacitated facility location, achieving promising results by closing significant gaps between continuous and optimal Lagrangian relaxations. The approach departs from traditional iterative algorithms, enhancing computational efficiency by leveraging predefined solutions from simpler problems as training data. Despite its innovative approach and technical soundness, the paper is critiqued for its lack of comparison with existing methods and reliance on self-generated datasets, raising concerns about generalizability and robustness. Reviewers are also concerned about the paper's narrow focus on specific MILP problems, which might limit the broader applicability of the proposed solution. Overall, while the paper presents a potentially industry-valuable strategy, its limited experimental validation and comparisons with baseline methods present significant drawbacks.\n\n**Strengths**\n- The proposed method demonstrates good generalization from training to testing datasets, offering effective predictions even with small datasets.\n- The approach soundly utilizes the Lagrangian dual to provide good lower bounds, which is an improvement over previous results in solving MILPs.\n- The framework accommodates variable input sizes and tests on relevant MILP problems, indicating a level of practical applicability.\n- The learned solutions can effectively warm-start bundle methods, potentially reducing computation times.\n- The deep learning architecture, while combining known techniques, presents a novel approach to predicting Lagrangian multipliers.\n- The method is more general compared to previous methods for predicting optimal Lagrange multipliers, indicating potential for broader impact in combinatorial optimization.\n\n**Weaknesses**\n- The paper lacks experimental comparison with other methods, which is critical for validating the claimed improvements and understanding its position within the field.\n- There is no citation of significant related works, such as those involving encoder-decoder refinements in training, which is a substantial gap in the literature review.\n- Experiments are conducted only on self-generated datasets, limiting the external validity and transparency of the results.\n- It remains unclear how beneficial the approach is compared to traditional integer programming solvers like Gurobi, as comprehensive runtime comparisons are missing.\n- Some technical contributions appear limited, with primary techniques already existing in the literature, contributing only incrementally to the field.\n- The problem instances used (MCDN, CFL) are somewhat specialized; more general and common MILPs should also have been tested to better assess the approach\u2019s applicability.\n\n**Questions**\n- Can you define the CR bound in your paper's context and clarify how the learned dual solution compares with the CR dual solution in terms of GAP and GAP-CR?\n- What was the inclusion of the bundle method warm-start and does this time accounting include the CR/DNN forward time?\n- How does the proposed approach perform against Gurobi in solving the MILP instances?\n- How competitively does the approach predict multipliers compared to simpler models like k-NN or other learning-based methods for Lagrangian dual variables?\n- Is there an explanation on how the method handles training without needing coefficients of the variables in MILP constraints which typically vary widely?\n- Are there plans to make the code and datasets available should the paper be accepted, to enable reproducibility and further research by others?",
        "inference_review": "**Summary**\nThe paper introduces a novel approach for predicting Lagrangian multipliers for mixed-integer linear programs (MILPs) using a graph neural network (GNN) architecture. The method involves encoding MILP instances into a bipartite graph, which is then processed by a GNN to generate constraint representations. These representations are subsequently decoded to predict Lagrangian multipliers, aiming to enhance the performance of Lagrangian relaxation. The paper presents experimental results on two specific MILP problems, showing potential benefits in terms of computational efficiency and bound quality. However, concerns about the generalizability of the approach and the experimental setup's robustness are raised.\n\n**Strengths**\n- The use of graph neural networks to predict Lagrangian multipliers is a novel and innovative approach, showing promise in improving the efficiency and effectiveness of solving mixed-integer linear programs.\n- The paper is well-structured and easy to follow, making complex concepts accessible to readers.\n- The proposed method is generalizable and can be applied to a wide variety of MILP problems, enhancing its practical utility.\n- Experiments conducted on two benchmark instances demonstrate the method's potential, showing significant improvements over traditional Lagrangian relaxation methods.\n- The idea of training a model to predict the Lagrangian dual is both interesting and challenging, and the paper effectively communicates this complexity.\n\n**Weaknesses**\n- The paper lacks a thorough comparison with existing methods, particularly those that also utilize graph neural networks, which could have provided a clearer demonstration of the proposed method's advantages.\n- The experimental setup is limited, focusing only on two specific instances of MILP problems. It would be beneficial to expand the experiments to include more diverse and challenging instances to better evaluate the method's robustness and effectiveness.\n- The paper does not sufficiently discuss the computational complexity of the proposed method, which is crucial for understanding its practical applicability.\n- The method relies heavily on pre-computed Lagrangian bounds, raising concerns about its efficiency and effectiveness when applied to problems where such bounds are not readily available or are computationally intensive to compute.\n- The paper suffers from poor presentation, with a number of figures and equations not clearly explained or labeled, which could hinder the understanding of the proposed method.\n\n**Questions**\n- Could the authors provide more details on how the graph neural network architecture is specifically designed for predicting Lagrangian multipliers and how it differs from other graph neural network architectures used for similar tasks?\n- How does the computational complexity of the proposed method compare to existing methods, and what are the specific challenges or limitations that arise during the implementation of this method?\n- Given that the method relies on pre-computed Lagrangian bounds, how does the proposed method perform when these bounds are not readily available or are computationally intensive to compute?\n- Can the authors clarify the presentation issues noted in the review, particularly with regards to figures and equations that are not clearly explained or labeled?\n- How does the proposed method perform on more diverse and challenging instances of MILP problems, and what are the results of these additional experiments?"
    },
    "xJ5N8qrEPl": {
        "gold_review": "**Summary**\nThis research presents a new single-loop Hessian-free algorithm for bi-level optimization (BLO) problems involving lower-level (LL) constraints coupling both upper and lower-level variables. This innovative approach utilizes the Moreau envelope value function, enabling a single-level reformulation with smooth constraints. This results in the proposed Lagrangian Value function-based Hessian-free Bi-level Algorithm (LV-HBA), which relaxes the strongly convex assumption on the lower-level problem to general convexity. The paper provides a detailed non-asymptotic convergence analysis and validates the effectiveness of the algorithm through extensive numerical experiments across various practical applications, highlighting its superior performance and computational efficiency.\n\n**Strengths**\n- The paper is well-written, with clear organization and elucidation of assumptions, which makes it easy to follow and understand both the primary concepts and the technical intricacies of the proposed approach.\n- The paper introduces the first single-loop Hessian-free algorithm for solving the bilevel optimization (BLO) problem, which includes a novel use of the Moreau envelope value function leading to an efficient gradient-based algorithm.\n- A new potential function associated with monotonically decreasing step sizes is presented, and methods to select these step sizes to ensure sufficient descent are demonstrated.\n- The authors include non-asymptotic convergence analysis for the proposed method and relax the lower level problem's requirements from strongly to only convex, increasing the method's applicability.\n- Extensive experimental results on five machine learning tasks validate the performance and demonstrate the efficiency of the proposed methods.\n\n**Weaknesses**\n- The paper includes many hyperparameters, which complicates practical implementation and parameter selection.\n- Some of the assumptions such as Assumption 3.1(i) and 3.3(ii) are considered too strong or unclear, which might limit the applicability of the proposed method in practical scenarios where these conditions are not met.\n- Comparisons with some recent significant works in constrained BLO through the value function approach are missing, which could provide a deeper contextual understanding of the paper's position within current research.\n- It is unclear whether the performance of the algorithm is overly sensitive to the stepsize parameters, and the choice of certain parameters like 'r' for the truncated proximal Lagrangian value function is not discussed.\n- The paper could benefit from more examples of bilevel optimization in machine learning with non-smooth and weakly convex lower level functions to better motivate and illustrate the approach.\n\n**Questions**\n- 1. Can the authors elaborate on why there is no need to assume Lipschitz continuity of the upper-level function F(x,y), which is typically necessary in bilevel optimization?\n- 2. How is the exact form of \u03c1f determined, especially in practical applications where it is potentially smaller than Lf?\n- 3. Can the authors clarify whether the optimal solutions of the reformulated and the original constrained BLO problem are equivalent, as suggested by Theorem A.1?\n- 4. How should the parameter 'r' be chosen in practical applications as mentioned in reformulation (5)?\n- 5. Could the authors provide insights into the central benefit of using the Moreau envelope as opposed to the optimal value function in the technical aspects of this work?\n- 6. How are the hyperparameters, including 'r', chosen in the experimental setups, and what guidance can the authors provide for their selection in practice?",
        "inference_review": "**Summary**\nThe paper introduces a novel method for solving constrained bi-level optimization problems by employing a smooth proximal Lagrangian value function to reformulate the lower-level problem into a single-level optimization problem with smooth constraints. This transformation enables the development of a Hessian-free gradient-based algorithm named LV-HBA, which offers a single-loop solution to constrained BLO problems. The paper also provides non-asymptotic convergence analysis for LV-HBA, eliminating the need for strong convexity assumptions at the lower level. Empirical results validate the algorithm's practical performance across various machine learning applications. The approach combines elements of previous methods and extends the value function reformulation to constrained problems, yet the novelty and depth of technical contributions are questioned, particularly in terms of its originality and the incremental nature of the proposed methods.\n\n**Strengths**\n- The paper introduces a new method for solving constrained bilevel optimization problems (BLOs) using a smooth proximal Lagrangian value function to reformulate the lower-level problem into a single-level optimization problem.\n- It presents a non-asymptotic convergence analysis for the proposed algorithm, which does not require strong convexity at the lower level, addressing a significant technical challenge.\n- The approach combines elements of existing methods and extends the value function reformulation to constrained problems, which could be beneficial for practical applications.\n- Empirical results provided in the paper demonstrate the practical performance of the algorithm in various machine learning applications.\n\n**Weaknesses**\n- The paper lacks a detailed comparison with existing methods and does not clearly articulate the main novelty of the proposed algorithm, making it difficult to understand its advantages over prior works.\n- The technical contributions are described as incremental, with the new method appearing to be a minor extension of previous works.\n- The presentation of the paper could be improved for clarity and readability, as some sections are difficult to follow.\n- The assumptions on the problem structure are restrictive, and it is unclear whether the results can be generalized to more complex scenarios.\n- The convergence analysis provided is limited to specific assumptions and does not consider more general or practical scenarios.\n\n**Questions**\n- Could you clarify what is the main novelty of your method and how it differs from and improves upon previous works?\n- How does the proposed algorithm perform in scenarios where the lower-level problem is non-convex or has more complex constraints?\n- Can you elaborate on the practical applicability of your method, especially in scenarios where the assumptions on problem structure are not met?\n- How does the proposed method handle scenarios where the lower-level problem is not strongly convex, and can you provide more details on the convergence behavior in such cases?\n- Could you provide a more detailed comparison with existing methods, particularly in terms of the computational efficiency and the assumptions required for convergence?\n- In the experimental section, how do the results compare with other methods like those cited in recent studies, such as those by Gao et al. (2023) and Kwon et al. (2023)?"
    },
    "You77eOFDv": {
        "gold_review": "**Summary**\nThe paper introduces a novel technique termed Re-parameterized Refocusing Convolution (RefConv), which enhances pre-trained models' performance without incurring additional inference costs. It does this by re-orienting convolution kernels to focus on novel representations. The approach involves incorporating additional learnable parameters during training that merge with the model\u2019s original parameters during inference. Despite evidence of improved effectiveness in several classic convolutional networks, concerns arose from limited validations against modern architectures and stronger baselines. Questions regarding iterative improvements and the genuine necessity of linking channel information remain inadequately addressed. The paper's effectiveness, especially in its validation against widely-acknowledged benchmarks and datasets like ImageNet, was a central point of contention among reviewers.\n\n**Strengths**\n- The approach in this paper is innovative, described as \"convolution B of convolution A\", where convolution A is pre-trained and kept frozen while convolution B continues to train.\n- The method demonstrates a slight advantage over several other structural reparameterization and weight reparameterization methods, supporting the claim that reparameterized refocusing reduces channel redundancy.\n- The paper includes a variety of experiments using different convolutional models which demonstrates the method's versatility.\n- The paper effectively utilizes visual aids, such as Figure 1, which clearly and effectively conveys the central concepts, and employs various visualization techniques to provide valuable insights.\n- There are no additional costs during the inference phase due to the seamless integration of parameters, which is beneficial from a practical standpoint.\n\n**Weaknesses**\n- Although there is about a 1% performance improvement on models like ResNet, DenseNet, and MobileNet, the solution introduces significantly more parameters, potentially compromising model efficiency.\n- The paper lacks experimental results on newer convolutional architectures such as SlaK, RepLKNet, and HorNet, which raises questions about the method's effectiveness on modern neural networks.\n- There is a higher computational cost noted during training without clear validation of the accuracy or reliability of this process, raising concerns about the practicality of the method.\n- The data from ImageNet, specifically in the experimental results shown in Table 1, is questioned for its accuracy and validity. The review suggests the data does not align well with data from standardized libraries such as timm.\n- The method's effectiveness is questioned under standard training procedures. It implies that it might only present advantages under specific, perhaps less optimal, training conditions.\n- The method is criticized for potentially being akin to providing more extensive training to an initially under-trained model, thereby questioning the necessity of the method if models are trained adequately by standard methods.\n\n**Questions**\n- Can the refocusing technique be iteratively applied multiple times, and if so, does it continue to improve results or reach a plateau?\n- What is the necessity and impact of possibly linking individual channels of the base weight (W_b), given each channel's specific role?\n- During the refocus training, is there any evidence from experiments on other models, especially newer convolution models, to suggest whether this approach degrades performance when compared to the original model's performance?\n- The authors are questioned on how accurately they incorporate results from iterative refocusing in their models and whether these align with advanced training practices like those provided in scholarly resources like timm?",
        "inference_review": "**Summary**\nThe paper introduces RefConv, a novel method aimed at enhancing performance in various computer vision tasks by re-parameterizing existing convolutional layers. This technique, inspired by the concept of \"re-parameterization,\" is designed to augment the representational capacity of pre-trained models by creating connections among kernel parameters. The method is evaluated across several datasets including ImageNet, object detection, and semantic segmentation, demonstrating improved performance without increasing inference costs. The paper also explores the effects of re-parameterization on loss landscapes and channel redundancy, suggesting a possible explanation for the observed performance improvements.\n\n**Strengths**\n- The concept of re-parameterization in convolutional layers is innovative and effectively demonstrates its utility in enhancing model performance.\n- The experimental results are convincing, showing improvements in top-1 accuracy across various models and tasks.\n- The method is simple, easy to understand, and straightforward, which facilitates its implementation and further exploration.\n- The paper is well-written, with clear explanations of the method and its implications, making it accessible and understandable to a broad audience.\n\n**Weaknesses**\n- The novelty of the re-parameterization method is limited, as it closely resembles existing methods, particularly those involving identity mappings.\n- The empirical evaluation lacks depth in terms of statistical significance and diversity of datasets. There is a need for more extensive experiments, especially with different datasets and a broader range of models.\n- The method's impact on computational efficiency and memory usage is not thoroughly investigated, which is crucial given the added complexity of the re-parameterization layer.\n- There is a lack of clarity on the choice of the transformation matrix and how it affects the model's performance, especially in terms of generalization across different tasks and datasets.\n- The paper does not sufficiently address the theoretical underpinnings of why the re-parameterization method improves performance, which could limit its appeal to researchers interested in deeper theoretical insights.\n\n**Questions**\n- How does the re-parameterization method compare to other similar techniques, such as those involving identity mappings, in terms of performance and computational efficiency?\n- Could you provide more details on the selection and influence of the transformation matrix in your experiments? Specifically, how does it vary across different tasks and datasets?\n- What are the effects of re-parameterization on computational efficiency and memory usage? Are there any significant impacts that could affect the practical deployment of the models?\n- How does the method generalize to other tasks and datasets beyond those tested in your experiments?\n- Can you clarify the theoretical rationale behind the observed improvements in model performance due to the re-parameterization method?\n- How does the proposed method compare to other re-parameterization techniques like those discussed in other recent works, such as the re-parameterization methods mentioned in the references?"
    },
    "pB1FeRSQxh": {
        "gold_review": "**Summary**\nThe paper presents a quantum algorithm for minimizing the maximum loss of N convex Lipchitz functions. It offers a quantum speedup by leveraging Gibbs sampling in the quantum optimization model with a structured presentation of key ideas, approaches, and bounds. The regularized ball optimization oracle, familiar from classical algorithms, is utilized in a new context providing a quantum advantage. The paper improves upon existing classical algorithms by achieving O~(N * epsilon^-5/3 + epsilon^-8/3) for the complexity, offering a quadratic speedup in terms of dependency on N, though still maintaining a worse dependency on epsilon compared to classical approaches. The paper includes a discussion on the gaps between the upper and lower bounds as an area for further exploration.\n\n**Strengths**\n- The paper presents an improved quantum algorithm for a foundational problem in convex optimization, making significant progress on a well-studied optimization task.\n- The use of quantum Gibbs sampling as a method to enhance the algorithm's performance is particularly interesting and novel.\n- The results reported are clear and informative, and the paper successfully demonstrates that quantum algorithms could potentially outperform classical counterparts under certain conditions.\n- It establishes that the dependence of the number of queries on the number of functions N is optimal up to logarithmic factors, which is a strong contribution to the field.\n- The paper is generally well-written, making it accessible for both quantum and non-quantum audience.\n\n**Weaknesses**\n- There is a notable gap between the upper and lower bounds which is unaddressed, affecting the completeness of the results.\n- The novelty of the algorithm is questionable as it largely entails the incorporation of a known quantum step into an existing classical algorithm framework.\n- The paper could benefit from a more polished presentation, particularly in improving the clarity of the language used which at times appears awkward or unclear.\n- Specific content, such as the presentation of certain equations and references, as well as the naming of elements could be streamlined for clarity and conciseness.\n- While the algorithm is optimal with respect to the number of functions N, it is not optimal concerning the error term (\\u03f5), where known classical algorithms reportedly perform better.\n\n**Questions**\n- Could you clarify the necessity of a rejection sampling procedure following the modifications in the quantum sampling algorithm (Algorithm 2) mentioned?\n- It would be beneficial to elaborate on the reasons for the existing gap between the upper and lower bounds, especially in comparison with classical algorithms.\n- Can you elaborate on how classical algorithms achieve better performance with respect to \\u03f5 and whether a more powerful oracle contributes to this?\n- Is there potential for a meta-theorem that generalizes the quadratic speedup observed in quantum algorithms to a broader class of computational/optimization problems, provided certain conditions are met in the classical algorithms employed?",
        "inference_review": "**Summary**\nThe paper investigates quantum algorithms for minimizing the maximum of N convex Lipschitz functions, addressing both the query complexity and the optimality of these algorithms. The authors propose a quantum algorithm that reduces the query complexity from O(N\u03b5^(-2/3) + \u03b5^(-8/3)) to O(\u221aN\u03b5^(-5/3) + \u03b5^(-8/3)), which is then complemented by a lower bound analysis indicating that these improvements are nearly optimal. However, concerns have been raised about the practicality of the quantum algorithm and its comparison to classical methods, as well as the clarity and presentation of the results.\n\n**Strengths**\n- The paper provides a solid analysis of the quantum query complexity for minimizing the maximum of N convex Lipschitz functions, which is a relevant and challenging problem.\n- It includes a lower bound analysis, showing that the query complexity is nearly optimal and contributing to the understanding of the limitations of quantum algorithms in this context.\n- The paper is well-organized, making it easy to follow, and the proofs are clear and understandable, with the main ideas presented in a straightforward manner.\n- It provides a new quantum algorithm that outperforms the classical algorithm in terms of query complexity, which is an interesting result that could potentially benefit future research.\n- The paper addresses the question of whether quantum algorithms can improve upon the classical methods for minimizing the maximum of N convex Lipschitz functions.\n\n**Weaknesses**\n- The paper does not adequately discuss the practical implications of the proposed quantum algorithm, particularly in terms of its feasibility and potential real-world applications.\n- There are concerns about the scalability of the algorithm as N increases, as the query complexity increases with N, which might limit its applicability in large-scale scenarios.\n- The presentation of the results could be improved; for instance, the claim that the quantum algorithm is the first to achieve a near-optimal query complexity is not supported by a detailed comparison with existing literature.\n- The paper could benefit from additional theoretical analysis to support the claims and to provide a more comprehensive understanding of the algorithm's efficiency and limitations.\n- The clarity of the presentation, especially in defining and explaining the problem setup and the algorithm's functionality, could be improved to enhance readability and comprehension for readers.\n\n**Questions**\n- Could the authors elaborate on the practical implications of their quantum algorithm and discuss its potential applications in real-world scenarios?\n- How does the scalability of the algorithm perform as N increases, and what are the implications for its query complexity?\n- Can the authors provide a more detailed comparison of their algorithm with existing literature to substantiate their claims about achieving a near-optimal query complexity?\n- What are the theoretical underpinnings that support the efficiency and effectiveness of the quantum algorithm?\n- Could the authors clarify the definition and functionality of the problem setup, including the minimization of the maximum of N convex Lipschitz functions, and explain how the quantum algorithm addresses this problem?"
    },
    "Ue93J8VV3W": {
        "gold_review": "**Summary**\nThe paper introduces eight graph datasets each containing 7-31 features per node and evaluates various machine learning models against these benchmarks, focusing on heterogeneous node features. Named 'TabGraph', the benchmarks provide a mix of feature types, node numbers, average degrees, and domains. The paper discusses the implementation of models like GNNs, tabular deep learning, and tree models, alongside a hybrid approach. Various recommendations and analyses are given for both tabular and graph machine learning fields. The contribution centers around bridging the gap between traditional tabular data modeling and newer graph-based machine learning techniques. However, the paper lacks in-depth theoretical insights and substantial novelty in methodology, bringing into question its authenticity and potential impact on the field.\n\n**Strengths**\n- The new datasets include useful node-level features, especially enriching existing benchmarks with additional attributes that add realism to the graph datasets.\n- The paper provides several benchmark datasets useful for machine learning models focusing on both tabular and graph-based approaches, along with combinations of the two.\n- There are valuable insights and recommendations for researchers and practitioners working with a mix of tabular and graph data.\n- The introduction of performance comparison across various machine learning models for tabular data and graph-based models highlights the applicability in real-world scenarios.\n- The paper effectively fills the gap between machine learning for tabular data and graph machine learning by comprising datasets of different kinds and attempting a comprehensive evaluation of major models.\n- The structure of the paper is commendable, making it a readable and approachable resource.\n\n**Weaknesses**\n- The paper lacks in-depth discussion on the rationale for dataset construction and does not thoroughly analyze the qualitative properties of newly created datasets.\n- There is a significant need for greater insight into the empirical study, which currently only presents results from base models without further analytical discussion.\n- The document does not effectively differentiate between transductive and inductive settings in its analysis, a distinction crucial for the applicability of graph neural networks and graph-based machine learning.\n- The paper's focus and contribution towards \"research\" are weak, leaning more towards being a dataset paper rather than offering significant advancements in graph learning.\n- There are unaddressed limitations, such as the conversion of relational data into graphs, the computational costs associated, and the non-inclusion of certain data types like strings or texts which are crucial in tabular data.\n- The methodology for dataset selection and preprocessing lacks clarity and comprehensiveness.\n- Insights provided are not entirely convincing due to the dataset being preprocessed by undisclosed rules.\n\n**Questions**\n- What was the specific criteria for the selection of these eight tabular datasets?\n- How does the paper address the difference between transductive and inductive learning methods, particularly in performance comparison?\n- Can the authors provide clarity on the comparative model performances on homogeneous features versus heterogeneous features to demonstrate the efficacy of the proposed datasets?\n- Why were strings or text data types not included in TabGraph, and how does this omission affect the benchmarks provided?\n- Could the authors explain their decision-making process regarding which features to include or exclude during dataset preprocessing, such as the number of votes in GBDT experiments?\n- What is the rationale behind the choice of thresholds for different datasets as mentioned in Section 3.1?\n- Is there a plan for adding at least one dataset from the science domain for node classification and regression tasks?\n- Can the importance of different types of features (number, binary, categorical) be comparatively analyzed in the paper?\n- What are the expected dates for the release of the source code and the datasets?\n- Could the authors elaborate on the resource implications of converting tabular data into graphs, considering computational limits and other constraints?",
        "inference_review": "**Summary**\nThe paper introduces a benchmark named TabGraphs, designed to evaluate machine learning models on tabular data structured as graphs, emphasizing the incorporation of heterogeneous features. This benchmark aims to fill the gap in existing datasets by offering a diverse set of graph datasets with heterogeneous node features, focusing on practical, real-world applications. The authors conducted extensive experiments using a variety of machine learning models, including traditional tabular models, deep learning models, and graph neural networks (GNNs). Their findings highlight the potential of graph models in enhancing predictive performance over traditional tabular models, particularly with the integration of feature embeddings and specific GNN architectures.\n\n**Strengths**\n- The paper addresses an important and timely issue of combining tabular and graph machine learning, which is highly relevant in the current research landscape.\n- The introduction of the TabGraphs benchmark, featuring a diverse set of datasets with heterogeneous features, is a significant contribution to the field, helping to bridge the gap between tabular and graph machine learning.\n- The experimental setup is thorough, providing a comprehensive evaluation of various machine learning models, including traditional tabular models, deep learning models, and graph neural networks.\n- The paper offers a clear and detailed explanation of the datasets and experimental setup, making it accessible and understandable to a broad audience.\n- The results presented in the paper are encouraging, showing that graph models can outperform traditional tabular models in many scenarios.\n\n**Weaknesses**\n- The paper lacks a clear motivation and justification for using tabular data structured as graphs, particularly in the context of the datasets used, which are not inherently graph-structured.\n- The experimental results are presented in a way that does not clearly distinguish between different models' performance, which could lead to confusion about the effectiveness of various approaches.\n- The literature review is insufficiently comprehensive, particularly regarding recent studies on node property prediction and graph learning for tabular data.\n- The paper does not sufficiently discuss the limitations of the proposed benchmark and does not compare the performance of the TabGraphs benchmark against other existing datasets or benchmarks.\n- Some of the terminology and notation used in the paper are unclear or inconsistent, which could hinder understanding and replication of the work.\n- The paper does not provide a clear justification for the choice of specific datasets or the exclusion of other relevant datasets, which could impact the perceived validity and generalizability of the results.\n\n**Questions**\n- Could you provide more details on the motivation behind using tabular data structured as graphs, especially considering the datasets used in your study?\n- How do you justify the choice of specific datasets for your study, and why were other datasets not included?\n- Could you clarify the notation used in the paper, particularly the use of \"R\" in equations and the notation of datasets?\n- Can you explain the decision-making process behind selecting the specific machine learning models for evaluation in your study?\n- Why was the evaluation of the benchmark limited to the models mentioned, and could you consider including a broader range of models in future studies?\n- Could you provide more details on the experimental setup, particularly the choice of metrics and the methodology for comparing the performance of different models?"
    }
}